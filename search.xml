<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[图片方案的选择]]></title>
    <url>%2F2018%2F08%2F11%2Fperformance-image-type%2F</url>
    <content type="text"><![CDATA[基础知识有损vs无损图片文件格式有可能会对图片的文件大小进行不同程度的压缩，图片的压缩分为有损压缩和无损压缩两种 有损压缩。指在压缩文件大小的过程中，损失了一部分图片的信息，也即降低了图片的质量，并且这种损失是不可逆的，我们不可能从有一个有损压缩过的图片中恢复出全来的图片。常见的有损压缩手段，是按照一定的算法将临近的像素点进行合并 无损压缩。指在压缩文件大小的过程中，图片的质量没有任何损耗。我们任何时候都可以从无损压缩过的图片中恢复出原来的信息 索引色vs直接色计算机在表示颜色的时候，有两种形式，一种称作索引颜色,一种称作直接颜色 索引色。用一个数字来代表（索引）一种颜色，在存储图片的时候，存储一个数字的组合，同时存储数字到图片颜色的映射。这种方式只能存储有限种颜色，通常是256种颜色，对应到计算机系统中，使用一个字节的数字来索引一种颜色 直接色。使用四个数字来代表一种颜色，这四个数字分别代表这个颜色中红色、绿色、蓝色以及透明度。现在流行的显示设备可以在这四个维度分别支持256种变化，所以直接色可以表示2的32次方种颜色。当然并非所有的直接色都支持这么多种，为压缩空间使用，有可能只有表达红、绿、蓝的三个数字，每个数字也可能不支持256种变化之多 点阵图vs矢量图 点阵图，也叫做位图，像素图。构成点阵图的最小单位是象素，位图就是由象素阵列的排列来实现其显示效果的，每个象素有自己的颜色信息，在对位图图像进行编辑操作的时候，可操作的对象是每个象素，我们可以改变图像的色相、饱和度、明度，从而改变图像的显示效果。点阵图缩放会失真，用最近非常流行的沙画来比喻最恰当不过，当你从远处看的时候，画面细腻多彩，但是当你靠的非常近的时候，你就能看到组成画面的每粒沙子以及每个沙粒的颜色 矢量图，也叫做向量图。矢量图并不纪录画面上每一点的信息，而是纪录了元素形状及颜色的算法，当你打开一付矢量图的时候，软件对图形象对应的函数进行运算，将运算结果[图形的形状和颜色]显示给你看。无论显示画面是大还是小，画面上的对象对应的算法是不变的，所以，即使对画面进行倍数相当大的缩放，其显示效果仍然相同(不失真) GIF全称Graphics Interchange Format，采用LZW压缩算法进行编码。是无损的、采用索引色的、点阵图GIF是无损的，采用GIF格式保存图片不会降低图片质量。但得益于数据的压缩，GIF格式的图片，其文件大小要远小于BMP格式的图片。文件小，是GIF格式的优点，同时，GIF格式还具有支持动画以及透明的优点。但，GIF格式仅支持8bit的索引色，即在整个图片中，只能存在256种不同的颜色GIF格式适用于对色彩要求不高同时需要文件体积较小的场景，比如企业Logo、线框类的图等。因其体积小的特点，现在GIF被广泛的应用在各类网站中 JPEG or JPGJPEG是有损的、采用直接色的、点阵图，不支持透明度JPEG图片格式的设计目标，是在不影响人类可分辨的图片质量的前提下，尽可能的压缩文件大小。这意味着JPEG去掉了一部分图片的原始信息，也即是进行了有损压缩。JPEG的图片的优点，是采用了直接色，得益于更丰富的色彩，JPEG非常适合用来存储照片，用来表达更生动的图像效果，比如颜色渐变。与GIF相比，JPEG不适合用来存储企业Logo、线框类的图。因为有损压缩会导致图片模糊，而直接色的选用，又会导致图片文件较GIF更大 PNG-8PNG全称Portable Network Graphics，PNG-8是PNG的索引色版本。PNG-8是无损的、使用索引色的、点阵图。PNG是一种比较新的图片格式，PNG-8是非常好的GIF格式替代者，在可能的情况下，应该尽可能的使用PNG-8而不是GIF，因为在相同的图片效果下，PNG-8具有更小的文件体积。除此之外，PNG-8还支持透明度的调节，而GIF并不支持。 现在，除非需要动画的支持，否则我们没有理由使用GIF而不是PNG-8。当然了，PNG-8本身也是支持动画的，只是浏览器支持得不好，不像GIF那样受到广泛的支持。可以看到PNG-8具有更好的透明度支持 PNG-24PNG-24是PNG的直接色版本。PNG-24是无损的、使用直接色的、点阵图。无损的、使用直接色的点阵图，听起来非常像BMP，是的，从显示效果上来看，PNG-24跟BMP没有不同。PNG-24的优点在于，它压缩了图片的数据，使得同样效果的图片，PNG-24格式的文件大小要比BMP小得多。当然，PNG24的图片还是要比JPEG、GIF、PNG-8大得多。虽然PNG-24的一个很大的目标，是替换JPEG的使用。但一般而言，PNG-24的文件大小是JPEG的五倍之多，而显示效果则通常只能获得一点点提升。所以，只有在你不在乎图片的文件体积，而想要最好的显示效果时，才应该使用PNG-24格式。另外，PNG-24跟PNG-8一样，是支持图片透明度的 SVG全称Scalable Vector Graphics，是无损的、矢量图。SVG跟上面这些图片格式最大的不同，是SVG是矢量图。这意味着SVG图片由直线和曲线以及绘制它们的方法组成。当你放大一个SVG图片的时候，你看到的还是线和曲线，而不会出现像素点。这意味着SVG图片在放大时，不会失真，所以它非常适合用来绘制企业Logo、Icon等。SVG是很多种矢量图中的一种，它的特点是使用XML来描述图片。借助于前几年XML技术的流行，SVG也流行了很多。使用XML的优点是，任何时候你都可以把它当做一个文本文件来对待，也就是说，你可以非常方便的修改SVG图片，你所需要的只需要一个文本编辑器 WebPWebP是谷歌开发的一种新图片格式，WebP是同时支持有损和无损压缩的、使用直接色的、点阵图。从名字就可以看出来它是为Web而生的，什么叫为Web而生呢？就是说相同质量的图片，WebP具有更小的文件体积。现在网站上充满了大量的图片，如果能够降低每一个图片的文件大小，那么将大大减少浏览器和服务器之间的数据传输量，进而降低访问延迟，提升访问体验。在无损压缩的情况下，相同质量的WebP图片，文件大小要比PNG小26%；在有损压缩的情况下，具有相同图片精度的WebP图片，文件大小要比JPEG小25%~34%；WebP图片格式支持图片透明度，一个无损压缩的WebP图片，如果要支持透明度只需要22%的格外文件大小。想象Web上的图片之多，百分之几十的提升，是非常非常大的优化。只可惜，目前只有Chrome浏览器和Opera浏览器支持WebP格式，所以WebP的应用并不广泛。为了使用更先进的技术，比如WebP图片格式，来压缩互联网上传输的数据流量，谷歌甚至提供了Chrome Data Compression Proxy，设置了Chrome Data Compression Proxy作为Web代理之后，你访问的所有网站中的图片，在经过Proxy的时候，都会被转换成WebP格式，以降低图片文件的大小 IconfontUnicode 码表是一个很大的表格，每个表格都对应一个 Unicode 字符，每个字符都有一个 Unicode 码值对应，如 “李” 对应 “\u674e”, “靖” 对应 “\u9756”。因为码表很大，有部分表格并没有对应的字符，但是它有自己的码值。iconfont 的制作，首先将绘制的图形（可以是一张图片、也可以是一个 svg 描述）通过工具或者程序生成文字icon，然后将文字icon对应到码表之中，为了不干预码表中已有的字符，我们通常会把文字icon对应到没有字符的表格中，最后导出我们额外对应的表格信息，生成iconfont 总结 GIF： 无损、索引色、点阵图，支持动画、透明 JPG or JPEG：有损、直接色、点阵图，不支持透明 PNG-8：无损、索引色、点阵图，支持透明 PNG-24：无损的、直接色、点阵图，支持透明 SVG：无损、矢量图 WEBP：支持有损和无损压缩的、使用直接色的、点阵图，支持透明，但浏览器兼容性不好 IconFont：被转为了字体，字体css可操纵 相同效果的图片花费空间从大到小的顺序： 大图片：PNG-24 &gt; JPG &gt; WEBP 小图标：PNG-8 &gt; SVG &gt; IconFont 动图：GIF 应用一般情况下 单色图标用iconfont 动图用gif 带透明的图用png 颜色色数较小的图片用svg，如图标 如按钮 颜色色数较小的图片、尺寸较小图片用png8，如图标 如按钮 如缩略图 需要尽量锐利的图片用png，如按钮 如形象广告 如有文字的图片 尺寸较大的图片用jpg，如横幅广告 如正文插图 只针对chrome 单色图标用iconfont 动图用gif 带透明的图用png 颜色色数较小的图标用svg，如扁平风格彩色图标 颜色色数较小的图片、尺寸较小图片用png8，如图标 如按钮 如缩略图 需要尽量锐利的图片用png，如按钮如 如形象广告 有文字的图片 尺寸较大的图片用webp，如横幅广告 如正文插图]]></content>
      <categories>
        <category>Frontend Performance</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Flux]]></title>
    <url>%2F2018%2F08%2F07%2Freact-flux%2F</url>
    <content type="text"><![CDATA[Flux是Facebook用于构建客户端Web应用程序的一个系统架构。它通过利用单向数据流来补充React的可组合视图组件。它更像是一种模式，而不是一个正式的框架 Predicatable code predicatable data (Flux) predicatable UI (React) 过程 用户访问 View View 发出用户的 Action Dispatcher 收到 Action，要求 Store 进行相应的更新 Store 更新后，发出一个change事件 View 收到change事件后，更新页面 Control/View 一个component 的loading state 在本component内处理 view只负责render数据，不对数据做任何处理 view只负责invoke Action 123456789101112131415161718_onNoticesStoreChange () &#123; if (this.state.isDeleting) &#123; Alert.onSuccess('删除公告成功'); &#125; else if (this.state.isEditing) &#123; Alert.onSuccess('更新公告成功'); &#125; else if (this.state.isAdding) &#123; Alert.onSuccess('发布公告成功'); &#125; this.setState(&#123; isLoading: false, notices: NoticesStore.data, modalType: '', isDeleting: false, isEditing: false, isAdding: false &#125;); this.refs.modal.close();&#125;, Action 不要在action里操作dom 只有view invoke Action 每个Action都是一个对象，包含一个actionType属性和一些其他属性（用来传递数据） Action中利用Dispatcher的把具体的动作（actionType）派发到Store 12345678910111213141516retrieveChannel () &#123; this.callApi('DataApi.getChannel', DataApi.getChannel.bind(this), (data) =&gt; &#123; AppDispatcher.dispatch(&#123; type: ActionTypes.RETRIEVE_CHANNEL_SUCCESS, data: data['data'] &#125;); &#125;, (error) =&gt; &#123; AppDispatcher.dispatch(&#123; type: ActionTypes.RETRIEVE_CHANNEL_ERROR, data: Error.generateFromHttpError(error) &#125;); &#125; );&#125; Dispatcher Dispatcher 的作用是将 Action 派发到 Store，即触发注册的回调方法callbacks 可以把它看作一个路由器，负责在 View 和 Store 之间，建立 Action 的正确传递路线 Dispatcher 只能有一个，而且是全局的 1234567891011121314151617import &#123;Dispatcher&#125; from 'flux';class AppDispatcher extends Dispatcher &#123; dispatch (payload) &#123; if (this.isDispatching()) &#123; window.setTimeout(() =&gt; &#123; super.dispatch(payload); &#125;); &#125; else &#123; super.dispatch(payload); &#125; &#125;&#125;module.exports = new AppDispatcher(); Store Store 保存整个应用的state状态。它的角色有点像 MVC 架构之中的Model store 只负责响应对应的action并存储或者更新数据，但不对数据做任何再加工，数据加工交给API层实现 store 的change事件是全局的，最好不同的数据用不同的store来存储（由同一个事件触发而变化的数据 称为同种数据）， 分别addChangeListener到相应的callback function， 以应对不同的变化且相互不干涉 12345678910111213141516171819202122232425262728293031323334353637383940414243import Immutable from 'immutable';import BaseStore from './BaseStore.js';import &#123;ActionTypes&#125; from '../Constants.js';import Category from '../models/Category.js';import AppDispatcher from '../dispatcher/AppDispatcher.js';class CategoriesStore extends BaseStore &#123; constructor () &#123; super(); &#125; reset () &#123; this._data = Immutable.List([]); &#125; update (data) &#123; var categories = data ? data.map(category =&gt; &#123; return new Category(category); &#125;) : []; this._data = Immutable.List(categories); &#125; registerDispatcher () &#123; super.registerDispatcher(); this._dispatcherToken = AppDispatcher.register(payload =&gt; &#123; switch(payload.type) &#123; case ActionTypes.RETRIEVE_CATEGORIES_SUCCESS: this.update(payload.data); this.emitChange(); break; case ActionTypes.RETRIEVE_CATEGORIES_ERROR: this.updateError(payload.data); this.emitError(); break; default: // do nothing break; &#125; &#125;); &#125;&#125; 优势 应用的状态必须独立出来放到 store 里面统一管理，通过侦听 action 来执行具体的状态操作。 视图组件变得很薄，只包含了渲染逻辑和触发 action 这两个职责 要理解一个 store 可能发生的状态变化，只需要看它所注册的 actions 回调就可以 单向数据流动：任何状态的变化都必须通过 action 触发，而 action 又必须通过 dispatcher 走，所以整个应用的每一次状态变化都会从同一个地方流过。Flux 的意义就在于强制让所有的状态变化都必须留下一笔记录，这样就可以利用这个来做各种 debug 工具、历史回滚等等]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>Flux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB - The Good, The Bad, and The Ugly]]></title>
    <url>%2F2018%2F08%2F04%2Fdatabase-MongoDB%2F</url>
    <content type="text"><![CDATA[For those who are new to MongoDB, it’s a NoSQL-Document database. Documents comprise sets of key-value pairs and are the basic unit of data in MongoDB. It is definitely one of the most popular NoSQL databases as of now. It’s widely accepted and fits a wide variety of use cases (though not all of them). In this article of the good, the bad, and the ugly, I would like to give a brief overview based on my experience with MongoDB during the past few years. The GoodSince MongoDB is as popular as it is today, there should be more good than the bad and the ugly. If not, developers wouldn’t accept it. Below are a few good things about MongoDB. Flexible Data ModelIn today’s dynamic use cases and ever-changing applications, having a flexible data model is a boon. A flexible data model means that there is no predefined schema, and the document can hold any set of values based on any key. Expressive Query SyntaxThe query language of MongoDB is very expressive and is easy to understand. Many would say that it’s not like SQL. But why should we stick to a SQL-like query language when we can move forward and be more expressive and simple? Easy to LearnMongoDB is easy to learn and quick to start with. The basic installation, setup, and execution doesn’t take more than a few hours. The more robust setup might be complex, but I will talk about it later. You should be able to use the MongoDB database with ease in your project. PerformanceQuery performance is one of the strong points of MongoDB. It stores most of the workable data in RAM. All data is persisted in the hard disk, but during a query, it does not fetch the data from the hard disk. It gets it from the local RAM and, hence, is able to serve much faster. Here, it is important to have the right indexes and enough RAM to benefit from MongoDB’s performance. Scalable and ReliableMongoDB is highly scalable, using shards. Horizontal scalability is a big plus in most NoSQL databases. MongoDB is no exception. It is also highly reliable due to its replica sets, and the data is replicated in more nodes asynchronously. Async DriversNonblocking IO using async drivers are essential in all modern applications that are built for speed. MongoDB has async driver support for most of the popular languages. DocumentationHaving a good documentation can make developers’ lives a lot easier, especially when the developer is new to the technology. MongoDB has superb documentation. Text SearchIf you are building a website that needs to search all of your data, text search is essential. For example, an eCommerce website with a text-search-enabled database can be a lot more lucrative for the users. Server-Side ScriptIf you need some operations to be performed on the server side and not in your application, you can do that in MongoDB. Put your list of mongo statements in a .js file and execute mongo yourFile.js. Documents = ObjectsThe good thing about having a document database is that your object can directly be stored as a single document in MongoDB. There is no need of an ORM here. The BadWe looked at the various good things about MongoDB. Below are the few bad things. I am sure the critics are more interested in this part. MongoDB can be evil if we use it in for an improper use case. TransactionsNowadays, there are very few applications that actually require transactions. But some applications still need it. MongoDB, unfortunately, does not support transactions. So if you need to update more than one document or collection per user request, don’t use MongoDB. It may lead to corrupted data, as there is no ACID guarantee. Rollbacks have to be handled by your application. No TriggersIn RDBMSs, we have the luxury of triggers, which have saved us in many cases. This luxury is missing in MongoDB. StorageMongoDB needs more storage than other popular databases. The introduction of WiredTiger in MongoDB 3.0 has solved the storage issue, but using WiredTiger may not be ideal for most of the applications. Disk CleanupMongoDB does not automatically clean up the disk space. So if the documents are rewritten or deleted, the disk space is not released. This happens during restart or has to be done manually. The UglySometimes, the ugly can be worse than the bad. It’s important to know the ugly part before using the technology. It does not stop you from using the product, but it can make your life very tough. Hierarchy of SelfIf you have a data model where an object can have recursive children (i.e., same object type is a child of an object and it keeps going for ‘n’ levels), the MongoDB document can become very ugly. Indexing, searching, and sorting these recursive embedded documents can be very hard. JoinsJoining two documents is also not simple in MongoDB. Though MongoDB 3.2 supports left outer joins (lookup), it is not yet mature. If your applications require pulling data from multiple collections in a single query, it might not be possible. Hence you have to make multiple queries, which might make your code look a bit messy. IndexingThough speed is advertised as a big plus of MongoDB, it is achievable only if you have the right indexes. If you end up having poorly implemented indexes or composite indexes in an incorrect order, MongoDB can be one of the slowest databases. If you have a lot of filter by and sort by fields, you may end up having a lot of indexes on a collection, which, of course, is not good. Duplicate DataYou may end up having a lot of duplicate data, as MongoDB does not support well-defined relationships. Updating this duplicate data can be hard and, also due to lack of ACID compliance, we might end up having corrupted data. ConclusionOverall, MongoDB is a good database, provided it suits your use case. If it does not, it can get very ugly. Try using it in the wrong place and you will get burned. Analyze it well and consult an expert. You will definitely enjoy using it when it’s right. As for the bad and the ugly parts, you can work around a few of them using the design patterns which I have explained in my article MongoDB Design Patterns. MongoDB Best PracticesA few MongoDB best practices are listed below: Hardware Ensure your working set fits in RAM. Use compression. Run a single MongoDB per server. Use SSDs for write-heavy applications. Data Model Store all data for a record in a single document. Avoid large documents. Avoid unnecessarily long field names. Eliminate unnecessary indexes. Remove indexes that are prefixes of other indexes. Application Update only modified fields. Avoid negation in queries. Run explain() for every complex query. Use covered queries when possible. Use bulk inserts when needed. Setup and Configuration Have at least one secondary and one arbiter. Set write concern to 2 when the data is critical. Havea daily dump of data for backup.]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 1.X]]></title>
    <url>%2F2018%2F07%2F28%2Fnetwork-HTTP1-x%2F</url>
    <content type="text"><![CDATA[持久连接HTTP 1.1 的一个主要改进就是引入了持久 HTTP 连接持久连接可以避免第二次 TCP 连接时的三次握手、消除另一次 TCP 慢启动的往返，节约 整整一次网络延迟比如TCP 连接要发送 N 次 HTTP 请求 没有持久连接，每次请求都会导致两次往返延迟 有持久连接，只有第一次请求会导致两次往返延迟，后续请求只会导致一次往返延迟 在启用持久连接的情况下，N 次请求节省的总延迟时间就是(N-1)×RTT HTTP 管道持久 HTTP 可以让我们重用已有的连接来完成多次应用请求，但多次请求必须严格 满足先进先出(FIFO)的队列顺序:发送请求，等待响应完成，再发送客户端队列 中的下一个请求。 HTTP 管道是一个很小但对上述工作流却非常重要的一次优化。 管道可以让我们把 FIFO 队列从客户端(请求队列)迁移到服务器(响应队列) 要理解这样做的好处，需要看下图 服务器处理完第一次请求后， 会发生了一次完整的往返:先是响应回传，接着是第二次请求。在此期间服务器空 闲。如果服务器能在处理完第一次请求后，立即开始处理第二次请求呢?甚至，如 果服务器可以并行或在多线程上或者使用多个工作进程，同时处理两个请求呢 局限性HTTP 1.x只能严格串行地返回响应。特别是，HTTP 1.x不允许一个连接上的多个 响应数据交错到达(多路复用)，因而一个响应必须完全返回后，下一个响应才会开 始传输。为说明这一点，我们可以看看服务器并行处理请求的情况图演示了如下几个方面: HTML 和 CSS 请求同时到达，但先处理的是 HTML 请求 服务器并行处理两个请求，其中处理HTML用时40ms，处理CSS用时20ms CSS 请求先处理完成，但被缓冲起来以等候发送 HTML 响应 发送完HTML响应后，再发送服务器缓冲中的CSS响应 即使客户端同时发送了两个请求，而且 CSS 资源先准备就绪，服务器也会先发送 HTML 响应，然后再交付 CSS。这种情况通常被称作队首阻塞，并经常导致次优化 交付:不能充分利用网络连接，造成服务器缓冲开销，最终导致无法预测的客户端 延迟。假如第一个请求无限期挂起，或者要花很长时间才能处理完，怎么办呢?在 HTTP 1.1 中，所有后续的请求都将被阻塞，等待它完成 问题 一个慢响应就会阻塞所有后续请求 并行处理请求时，服务器必须缓冲管道中的响应，从而占用服务器资源，如果有个响应非常大，则很容易形成服务器的受攻击面 响应失败可能终止TCP连接，从页强迫客户端重新发送对所有后续资源的请求，导致重复处理 由于可能存在中间代理，因此检测管道兼容性，确保可靠性很重要 如果中间代理不支持管道，那它可能会中断连接，也可能会把所有请求串联起来 使用多个TCP连接浏览器开发商允许我们并行打开多个 TCP会话大多数现代浏览器，包括桌面和移动浏览器，都支持每个 主机打开 6 个连接 域名分区HTTP 1.x协议的一项空白强迫浏览器开发商引入并维护着连接池，每个主机最多6 个 TCP 流。好的一方面是对这些连接的管理工作都由浏览器来处理。作为应用开发 者，你根本不必修改自己的应用。不好的一方面呢，就是 6 个并行的连接对你的应 用来说可能仍然不够用 根据HTTP Archive的统计，目前平均每个页面都包含90多个独立的资源，如果这 些资源都来自同一个主机，那么仍然会导致明显的排队等待 实际上， 何必把自己只限制在一个主机上呢?我们不必只通过一个主机(例如 www.example. com)提供所有资源，而是可以手工将所有资源分散到多个子域名:{shard1, shardn}.example.com。由于主机名称不一样了，就可以突破浏览器的连接限制，实 现更高的并行能力。域名分区使用得越多，并行能力就越强! 当然，天下没有免费的午餐，域名分区也不例外:每个新主机名都要求有一次额外 的 DNS 查询，每多一个套接字都会多消耗两端的一些资源，而更糟糕的是，站点作 者必须手工分离这些资源，并分别把它们托管到多个主机上 实践中，把多个域名(如 shard1.example.com、shard2.example.com)解析 到同一个IP地址是很常见的做法。所有分区都通过CNAME DNS记录指 向同一个服务器，而浏览器连接限制针对的是主机名，不是 IP 地址。另 外，每个分区也可以指向一个 CDN 或其他可以访问到的服务器 缺点 更多的套接字会占用客户端、服务器以及代理的资源，包括内存缓冲区和CPU 时钟周期 并行TCP流之间竞争共享的带宽 由于处理多个套接字，实现复杂性更高 即使并行TCP流，应用的并行能力也受限制]]></content>
      <categories>
        <category>Network</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HTTP 2.0]]></title>
    <url>%2F2018%2F07%2F28%2Fnetwork-http2-0%2F</url>
    <content type="text"><![CDATA[HTTP 2.0 相比于 HTTP 1.X，可以说是大幅度提高了 web 的性能。 在 HTTP 1.X 中，为了性能考虑，我们会引入雪碧图、将小图内联、使用多个域名等等的方式。这一切都是因为浏览器限制了同一个域名下的请求数量，当页面中需要请求很多资源的时候，队头阻塞（Head of line blocking）会导致在达到最大请求数量时，剩余的资源需要等待其他资源请求完成后才能发起请求在 HTTP 1.X 中，因为队头阻塞的原因，你会发现请求是这样的在 HTTP 2.0 中，因为引入了多路复用，你会发现请求是这样的 队首阻塞就是需要排队，队首的事情没有处理完的时候，后面的人都要等着 http1.0的队首阻塞对于同一个tcp连接，所有的http1.0请求放入队列中，只有前一个请求的响应收到了，然后才能发送下一个请求。 可见，http1.0的队首组塞发生在客户端 http1.1的队首阻塞对于同一个tcp连接，http1.1允许一次发送多个http1.1请求，也就是说，不必等前一个响应收到，就可以发送下一个请求，这样就解决了http1.0的客户端的队首阻塞。但是，http1.1规定，服务器端的响应的发送要根据请求被接收的顺序排队，也就是说，先接收到的请求的响应也要先发送。这样造成的问题是，如果最先收到的请求的处理时间长的话，响应生成也慢，就会阻塞已经生成了的响应的发送。也会造成队首阻塞。 可见，http1.1的队首阻塞发生在服务器端 http2是怎样解决队首阻塞的http2无论在客户端还是在服务器端都不需要排队，在同一个tcp连接上，有多个stream，由各个stream发送和接收http请求，各个steam相互独立，互不阻塞。 只要tcp没有人在用那么就可以发送已经生成的requst或者reponse的数据，在两端都不用等，从而彻底解决了http协议层面的队首阻塞问题 二进制传输HTTP 2.0 中所有加强性能的核心点在于此。在之前的 HTTP 版本中，我们是通过文本的方式传输数据。在 HTTP 2.0 中引入了新的编码机制，所有传输的数据都会被分割，并采用二进制格式编码 多路复用在 HTTP 2.0 中，有两个非常重要的概念，分别是帧（frame）和流（stream） 帧代表着最小的数据单位，每个帧会标识出该帧属于哪个流，流也就是多个帧组成的数据流。 多路复用，就是在一个 TCP 连接中可以存在多条流。换句话说，也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能 Notes 所有通信在一个TCP连接上完成 流是一个虚拟信道，每个流都有一个唯一的整数标识符 消息指逻辑上的HTTP消息，比如请求和响应，由一个或者多个帧组成 帧是最小的通信单位，承载着特定类型的数据，如HTTP header、负荷等 客户端发起的流偶数ID，srever端奇数 HTTP2把HTTP通信的基本单位缩小为一个个帧，这些帧组成 流 中所传输的 消息。很多流可以并发的在同一个TCP连接上交换消息HTTP2虽然只有一条TCP连接，但是在逻辑上分成了很多stream。HTTP2把要传输的信息分割成一个个二进制帧，首部信息会被封装到HEADER frame，相应的request body就放到DATA frame,一个帧你可以看成路上的一辆车,只要给这些车编号，让1号车都走1号门出，2号车都走2号门出，就把不同的http请求或者响应区分开来了。但是，这里要求同一个请求或者响应的帧必须是有有序的，要保证FIFO的，但是不同的请求或者响应帧可以互相穿插。这就是HTTP2的多路复用，是不是充分利用了网络带宽，是不是提高了并发度 单一长连接在HTTP/2中，客户端向某个域名的服务器请求页面的过程中，只会创建一条TCP连接，即使这页面可能包含上百个资源。 单一的连接应该是HTTP2的主要优势，单一的连接能减少TCP握手带来的时延 。HTTP2中用一条单一的长连接，避免了创建多个TCP连接带来的网络开销，提高了吞吐量 Header 压缩在 HTTP 1.X 中，我们使用文本的形式传输 header，在 header 携带 cookie 的情况下，可能每次都需要重复传输几百到几千的字节。 在 HTTP 2.0 中，使用了 HPACK 压缩格式对传输的 header 进行编码，减少了 header 的大小。并在两端维护了索引表，用于记录出现过的 header ，后面在传输过程中就可以传输已经记录过的 header 的键名，对端收到数据后就可以通过键名找到对应的值 服务端 PushHTTP 2.0 新增的一个强大的新功能，就是服务器可以对一个客户端请求发送多个响应。换句话说，除了对最初请求的响应外，服务器还可以额外向客户端推送资源，而无需客户端明确地请求为什么需要这样一个机制呢？通常的 Web 应用都由几十个资源组成，客户端需要分析服务器提供的文档才能逐个找到它们那为什么不让服务器提前就把这些资源推送给客户端，从而减少额外的时间延迟呢？服务器已经知道客户端下一步要请求什么资源了，这时候服务器推送即可派上用场。事实上，如果你在网页里嵌入过 CSS、JavaScript，或者通过数据 URI 嵌入过其他资源，那你就已经亲身体验过服务器推送了]]></content>
      <categories>
        <category>Network</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Certificate Authority]]></title>
    <url>%2F2018%2F07%2F28%2Fsecurity-CA%2F</url>
    <content type="text"><![CDATA[证书授权中心（certificate authority，CA）是管理和签发安全凭证和加密信息安全密钥的网络机构 证书的生成过程 CA将 申请者的信息、申请者的public key、要使用签名算法、签名hash算法等 用里面声明的签名hash算法生成一个digest CA用自己的private key 对这个digest加密生成signature 将这个signature 附在1中所有信息的后面 组合成 申请者的 digital certificate，然后返回给申请者 一个digital certificate如下图（知乎的）上图可以看出 知乎这个证书 里面的public key是明文的，加密的只是 digest所以digital certificate的作用是将持有者的公钥和持有者的身份绑定起来，CA的签名是保证了这个绑定关系。 证书应用在https中，client拿到server端的digital certificate后，用digital certificate中的hash算法对内容进行hash，得到一个digest，另一方面 用CA的公钥去 解密 signature，得到另一个digest，看前后生成的digest是否一样进而判断是否secure。 Notes 数字证书的作用是将持有者的公钥和持有者的身份绑定起来，CA的签名是保证了这个绑定关系 证书(digital certificate)中“网站公钥”是明文出现的，CA并不对网站公钥进行加密 CA对上面这一堆数据的一个摘要(digest)，用自己的私钥加密，产生的密文就是数字签名(signature)，附在上面这一堆明文的后面（对摘要进行加密） 由于CA的公钥每个人都持有，所以每个人都可以验证，证书中的这一堆信息是不是真实的（使用CA的公钥解密得到消息摘要，与自己计算出的消息摘要比对） 证书中，某人声明他的身份，并且附上了自己的公钥——这个身份与公钥的绑定，是由CA来验证的——证书持有者的公钥的真实性是由CA来保证的 CA链子CA的真实性是由上一级CA来保证的一级一级往上推，最终的问题是：根CA的真实性是谁来保证的？根CA可以给下一级CA签发证书，保证下一级CA的真实性，但根CA自己的真实性——可以说是由他自己保证的比如这个是12306的根证书：根证书的颁发者就是证书的使用者浏览器里一般预置有绝大多数根CA的证书，所以遇到其他网站的证书，可以通过证书路径，一级级往下验证，建立信任链。比如知乎的证书但遇到某些奇葩的网站，比如12306，由于该网站的根CA并没有预存在浏览器中，那么浏览器就无法建立信任链——所以登入12306时候会提示证书错误 安全 浏览器预存的根CA的证书是不是真实的？ 这个所谓的根CA是不是靠谱的 某些恶意的浏览器可能会预置一些虚假的根CA的证书——但这属于法律层面的问题。对于使用者而言，有两条建议 不使用野路子的浏览器 不轻易安装未知的根证书 这两点满足之后，至少可以保证：持有虚假证书的网站，是不会通过浏览器的信任检查的]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>CA</tag>
        <tag>Digital Certificate</tag>
        <tag>Signature</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTPS]]></title>
    <url>%2F2018%2F07%2F28%2Fsecurity-HTTPS%2F</url>
    <content type="text"><![CDATA[HTTPS 还是通过了 HTTP 来传输信息，但是信息通过 TLS（Transparent Layer Security） 协议进行了加密 TLSTLS 协议位于传输层之上，应用层之下。首次进行 TLS 协议传输需要两个 RTT ，接下来可以通过 Session Resumption 减少到一个 RTT。 在 TLS 中使用了两种加密技术，分别为：对称加密和非对称加密。 对称加密对称加密就是两边拥有相同的秘钥，两边都知道如何将密文加密解密 非对称加密有公钥私钥之分，公钥所有人都可以知道，可以将数据用公钥加密，但是将数据解密必须使用私钥解密，私钥只有分发公钥的一方才知道 TLS 握手过程 客户端 (浏览器) 发起 HTTP 请求，请求连接服务端，发送支持的加密通信协议 (和版本)，并且生成一个随机数，后续用于生成”对话密钥”。 服务端确认加密通信协议 (和版本)，同时也生成一个随机数，后续用于生成”对话密匙”，并且将 CA 颁发的数字证书，一起发送给客户端。 客户端收到数字证书后，检测内置的”受信任的根证书颁发机构”，查看解开数字证书的公匙是否在。 如果解开数字证书的公匙存在，则使用它解开数字证书，得到正确的服务器公匙，同时再次生成一个随机数，用于服务器公匙加密，并发送给服务器。 此时本地和服务器同时将三个随机数，根据约定的加密方法进行加密，各自生成本次会话的所使用的同一把 “会话密匙” 。 到这里，认证阶段已经完毕，数据传输从 非对称加密 换成了 对称加密 (因为考虑到性能)，接下来所有的数据传输都是使用HTTP协议进行传输，只不过使用了 “会话密匙” 来加密内容 TLS加密了什么除了domain，都加密了，包括 path query body header 等 与HTTP比较 安全性 HTTP HTTPS 窃听风险 传递的信息是明文的，可能会被有心人拦截下来窃听 信息加密传播 篡改风险 传递的信息可能会被篡改 信息校验，一旦被篡改立刻就会被发现 伪装风险 没有验证通信另外一头对方的身份，可能遭遇伪装 身份校验]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>TLS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[央行的调节工具]]></title>
    <url>%2F2018%2F07%2F27%2Feconomics-MLF%2F</url>
    <content type="text"><![CDATA[央妈最常用法宝公开市场操作，是指央妈通过在公开市场上拿钱买卖有价证券，来调节货币供应量和利率。这法宝其实是个百宝箱，央妈不断鼓捣出了很多小玩意儿，使用起来比较灵便，效果比较温和。最初主要是回购，后来补充了很多工具，有些还挺国际范儿。2013年初，央妈创设了常备借贷便利（SLF），2014年1月引入了短期流动性调节工具（SLO），2014年4月份创设了抵押补充贷款（PSL），2014年9月份创设了中期借贷便利（MLF），2015年10月，又扩大信贷资产质押再贷款扩围。百宝箱的工具越来越丰富多样。 异同下面我们打开百宝箱，来看看这些新奇的工具。我们可以先从三个方面整理比较下： 工具时间长短不同下图直观地显示了各类工具的贷款期限长度（图中圆点表示主要操作期限，三角形是辅助操作期限），从短到长分别为SLO(1-6天)，正/逆回购（7、14、28天）、SLF（一般1-3个月，1、7日较少），MLF（3个月到1年），PSL（3年到5年）。 工具作用不同不同长短的工具用来引导相应不同期限的利率，对应的，SLO引导超短期利率；逆回购引导短期利率，必要时用SLF调整；MLF引导中期利率。但有时央妈也会连续通过期限短的工具解决下稍长期的利率问题。此外，央妈也会通过调剂不同工具的使用量，来调整市场上资金的平均利率高低。 使用范围不同从窄到宽依次是PSL（政策性银行），MLF（政策性银行、商业银行），SLF与SLO（大中型金融机构）。 工具细节回购包括正回购和逆回购，这是央行最常用的工具。逆回购是指央行出钱，买交易商的证券，这样市场上钱就多了，同时约定几天后（7日为主，常态化操作，14、28日为辅），央行再按照原价加一定利息（按一定利率即逆回购利率计算）把券卖给交易商。正回购是指央行卖证券给交易商，交易商给央行钱，这样市场上的钱就少了，同时约定几天后央行再按照最初价加上利息买回来。这样，央行通过控制正/逆回购的节奏、规模、利率，来调节市场上钱的供应量和短期利率水平。（正回购、逆回购的作用经常会搞混，大家只要记住，“水逆水逆”，放水的逆回购，逆回购就是给市场放水，钱就多了） 短期流动性调节工具（Short-term Liquidity Operations，SLO）（为了好记，姑且称为小“酸辣圈”吧）这是用来调节比7天更短的货币供应和利率，也是采用回购的方式，时间从1天到6天都有。例如，2013年12月底，临近年末资金紧张，央行连续5天进行了SLO操作向市场投放钱，将资金利率缓和下来。 常备借贷便利（Standing LendingFacility，SLF），市场俗称“酸辣粉”大型金融机构缺钱了，可以向央行一对一申请抵押贷款，期限一般是1到3个月。一般在市场缺钱的时候，才用SLF来补充流动性，例如2013年下半年；市场不缺钱的是有一般不用，例如2016年第三季度仅操作了22.5亿元。央行可以通过SFL进行短期利率引导，将其作为“利率走廊”上限（下限是超额存款准备金率），就是说，如果市场利率大于某个值，有可能触发央妈强制使用，阻止金融机构之间的拆借，转向央行贷款。这个工具不常用，平常备着，所以叫“常备”。 中期借贷便利（Medium-term Lending Facility，MLF），俗称“麻辣粉”这工具要求借钱的银行投放于三农和小微贷款，期限一般为3个月、6个月和1年。MLF的量很大，央行每月进行常态化操作，2016年前三季度累计开展操作 3.2万亿元，期末余额为 1.9万亿元，成为基础货币供给的重要渠道，并以此引导中期利率。（央妈喜欢麻辣粉多于酸辣粉） 抵押补充贷款（Pledged Supplementary Lending，PSL），就称为“颇酸辣”吧央妈为了支持特定政策性银行完成国家重点项目（例如国开行的棚改项目），直接提供一部分低成本抵押资金，期限是3-5年，这就是抵押补充贷款。 随着利率市场化的推进，为了提高货币调控效果，央妈的百宝箱还在不断丰富着]]></content>
      <categories>
        <category>Economics</category>
      </categories>
      <tags>
        <tag>MLF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UDP原理]]></title>
    <url>%2F2018%2F07%2F25%2Fnetwork-UDP%2F</url>
    <content type="text"><![CDATA[面向报文UDP 是一个面向报文（报文可以理解为一段段的数据）的协议。意思就是 UDP 只是报文的搬运工，不会对报文进行任何拆分和拼接操作 具体来说 在发送端，应用层将数据传递给传输层的 UDP 协议，UDP 只会给数据增加一个 UDP 头标识下是 UDP 协议，然后就传递给网络层了 在接收端，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作 不可靠性 UDP 是无连接的，也就是说通信不需要建立和断开连接 UDP 也是不可靠的。协议收到什么数据就传递什么数据，并且也不会备份数据，对方能不能收到是不关心的 UDP 没有拥塞控制，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP 高效因为 UDP 没有 TCP 那么复杂，需要保证数据不丢失且有序到达。所以 UDP 的头部开销小，只有八字节，相比 TCP 的至少二十字节要少得多，在传输数据报文时是很高效的。头部包含了以下几个数据 两个十六位的端口号，分别为源端口（可选字段）和目标端口 整个数据报文的长度 整个数据报文的检验和（IPv4 可选 字段），该字段用于发现头部信息和数据中的错误 传输方式UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能。 与TCP区别 UDP无连接 UDP尽最大努力交付，不保证可靠交付 UDP没有拥塞控制 UDP首部开销小 UDP支持一对一，一对多，多对一和多对多的交互通信 不保证消息交付不确认，不重传，无超时 不保证交付顺序不设置包序号，不重排，不会发生队首阻塞 不跟踪连接状态不必建立连接或重启状态机 不需要拥塞控制不内置客户端或网络反馈机制]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP原理]]></title>
    <url>%2F2018%2F07%2F24%2Fnetwork-tcp%2F</url>
    <content type="text"><![CDATA[头部对于 TCP 头部来说，以下几个字段是很重要的 Sequence number，这个序号保证了 TCP 传输的报文都是有序的，对端可以通过序号顺序的拼接报文 Acknowledgement Number，这个序号表示数据接收端期望接收的下一个字节的编号是多少，同时也表示上一个序号的数据已经收到 Window Size，窗口大小，表示还能接收多少字节的数据，用于流量控制 标识符 ACK=1：该字段为一表示确认号字段有效。此外，TCP 还规定在连接建立后传送的所有报文段都必须把 ACK 置为一 SYN=1：当SYN=1，ACK=0时，表示当前报文段是一个连接请求报文。当SYN=1，ACK=1时，表示当前报文段是一个同意建立连接的应答报文 FIN=1：该字段为一表示此报文段是一个释放连接的请求报文 建立连接三次握手在 TCP 协议中，主动发起请求的一端为客户端，被动连接的一端称为服务端。不管是客户端还是服务端，TCP 连接建立完后都能发送和接收数据，所以 TCP 也是一个全双工的协议 起初，两端都为 CLOSED 状态。在通信开始前，双方都会创建 TCB(传输控制块Transmission Control Block)。 服务器创建完 TCB 后遍进入 LISTEN 状态，此时开始等待客户端发送数据。 第一次握手客户端选择一个随机序列号x，报文中SYN为1。请求发送后，客户端便进入 SYN-SENT 状态 第二次握手服务端收到连接请求报文段后，如果同意连接，则会发送一个应答，该应答中SYN 和 ACK 都置为1，并且给x+1，同时生成一个自己的随机数y，发送完成后便进入 SYN-RECEIVED 状态 第三次握手当客户端收到连接同意的应答后，还要向服务端发送一个确认报文。这个报文中ACK为1，并且给x 和 y 都 加 1客户端发完这个报文段后便进入ESTABLISHED 状态，服务端收到这个应答后也进入 ESTABLISHED 状态，此时连接建立成功。 为什么还需要第三次应答因为这是为了防止失效的连接请求报文段被服务端接收，从而产生错误。 可以想象如下场景。客户端发送了一个连接请求 A，但是因为网络原因造成了超时，这时 TCP 会启动超时重传的机制再次发送一个连接请求 B。此时请求顺利到达服务端，服务端应答完就建立了请求。如果连接请求 A 在两端关闭后终于抵达了服务端，那么这时服务端会认为客户端又需要建立 TCP 连接，从而应答了该请求并进入 ESTABLISHED 状态。此时客户端其实是 CLOSED 状态，那么就会导致服务端一直等待，造成资源的浪费。 PS：在建立连接中，任意一端掉线，TCP 都会重发 SYN 包，一般会重试五次，在建立连接中可能会遇到 SYN FLOOD 攻击。遇到这种情况你可以选择调低重试次数或者干脆在不能处理的情况下拒绝请求。 拥塞处理拥塞处理和流量控制不同，后者是作用于接收方，保证接收方来得及接受数据。而前者是作用于网络，防止过多的数据拥塞网络，避免出现网络负载过大的情况。 拥塞处理包括了四个算法，分别为：慢开始，拥塞避免，快速重传，快速恢复。cwnd（拥塞窗口）ssthresh（慢开始门限） 慢开始算法慢开始算法，顾名思义，就是在传输开始时将发送窗口慢慢指数级扩大，从而避免一开始就传输大量数据导致网络拥塞 慢开始算法步骤具体如下 连接初始设置拥塞窗口（Congestion Window） 为 1 MSS（一个分段的最大数据量） 每过一个 RTT 就将窗口大小乘二 指数级增长肯定不能没有限制的，所以有一个阈值限制，当窗口大小大于阈值时就会启动拥塞避免算法。 拥塞避免算法拥塞避免算法相比简单点，每过一个 RTT 窗口大小只加一，这样能够避免指数级增长导致网络拥塞，慢慢将大小调整到最佳值。在传输过程中可能定时器超时的情况，这时候 TCP 会认为网络拥塞了，会马上进行以下步骤： 将阈值设为当前拥塞窗口的一半 将拥塞窗口设为 1 MSS 启动慢开始算法 快重传 快重传算法要求首先接收方收到一个失序的报文段后就立刻发出重复确认，而不要等待自己发送数据时才进行捎带确认。接收方成功的接受了发送方发送来的M1、M2并且分别给发送了ACK，现在接收方没有收到M3，而接收到了M4，显然接收方不能确认M4，因为M4是失序的报文段。如果根据可靠性传输原理接收方什么都不做，但是按照快速重传算法，在收到M4、M5等报文段的时候，不断重复的向发送方发送M2的ACK,如果接收方一连收到三个重复的ACK,那么发送方不必等待重传计时器到期，由于发送方尽早重传未被确认的报文段。 快恢复 当发送发连续接收到三个确认时，就执行乘法减小算法，把慢启动开始门限（ssthresh）减半，但是接下来并不执行慢开始算法 此时不执行慢启动算法，而是把cwnd设置为ssthresh的一半， 然后执行拥塞避免算法，使拥塞窗口缓慢增大 Hintcwnd（拥塞窗口）是发送方维持的一个值rwnd（接收窗口）是接收方维持的一个值实际发送速率是min(cwnd, rwnd)接收窗口会随每次 ACK 一起发送，而拥塞窗口则由发送端根据拥塞控制和预防算法动态调整 总结 TCP 三次握手增加了整整一次往返时间 TCP 慢启动将被应用到每个新连接 TCP 流量及拥塞控制会影响所有连接的吞吐量 TCP 的吞吐量由当前拥塞窗口大小控制 优化大多数情况下，TCP 的瓶颈都是延迟，而非带宽 把服务器内核升级到最新版本(Linux:3.2+) 确保 cwnd 大小为 10 禁用空闲后的慢启动 确保启动窗口缩放 减少传输冗余数据 压缩要传输的数据 把服务器放到离用户近的地方以减少往返时间 尽最大可能重用已经建立的 TCP 连接]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React setState]]></title>
    <url>%2F2018%2F07%2F24%2Freact-setState%2F</url>
    <content type="text"><![CDATA[setState 在 React 中是经常使用的一个 API，但是它存在一些问题，可能会导致犯错，核心原因就是因为这个 API 是异步的。 首先 setState 的调用并不会马上引起 state 的改变，并且如果你一次调用了多个 setState ，那么结果可能并不如你期待的一样12345678handle() &#123; // 初始化 `count` 为 0 console.log(this.state.count) // -&gt; 0 this.setState(&#123; count: this.state.count + 1 &#125;) this.setState(&#123; count: this.state.count + 1 &#125;) this.setState(&#123; count: this.state.count + 1 &#125;) console.log(this.state.count) // -&gt; 0&#125;第一，两次的打印都为 0，因为 setState 是个异步 API，只有同步代码运行完毕才会执行。setState 异步的原因我认为在于，setState 可能会导致 DOM 的重绘，如果调用一次就马上去进行重绘，那么调用多次就会造成不必要的性能损失。设计成异步的话，就可以将多次调用放入一个队列中，在恰当的时候统一进行更新过程第二，虽然调用了三次 setState ，但是 count 的值还是为 1。因为多次调用会合并为一次，只有当更新结束后 state 才会改变，三次调用等同于如下代码123456Object.assign( &#123;&#125;, &#123; count: this.state.count + 1 &#125;, &#123; count: this.state.count + 1 &#125;, &#123; count: this.state.count + 1 &#125;,)当然你也可以通过以下方式来实现调用三次 setState 使得 count 为 312345handle() &#123; this.setState((prevState) =&gt; (&#123; count: prevState.count + 1 &#125;)) this.setState((prevState) =&gt; (&#123; count: prevState.count + 1 &#125;)) this.setState((prevState) =&gt; (&#123; count: prevState.count + 1 &#125;))&#125;如果你想在每次调用 setState 后获得正确的 state ，可以通过如下代码实现12345handle() &#123; this.setState((prevState) =&gt; (&#123; count: prevState.count + 1 &#125;), () =&gt; &#123; console.log(this.state) &#125;)&#125;]]></content>
      <categories>
        <category>React</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CSRF Protection in Rails ( ActionController::RequestForgeryProtection )]]></title>
    <url>%2F2018%2F07%2F24%2Fsecurity-ROR-CSRF%2F</url>
    <content type="text"><![CDATA[The BasicsThere are two components to CSRF. First, a unique token is embedded in your site’s HTML. That same token is also stored in the session cookie. When a user makes a POST request, the CSRF token from the HTML gets sent with that request. Rails compares the token from the page with the token from the session cookie to ensure they match. Generation encrypted token and embedded into form Token generation(raw token) &amp; Store into session123456#actionpack/lib/action_controller/metal/request_forgery_protection.rbdef real_csrf_token(session) # :doc: session[:_csrf_token] ||= SecureRandom.base64(AUTHENTICITY_TOKEN_LENGTH) Base64.strict_decode64(session[:_csrf_token])end Token encryption123456789101112def masked_authenticity_token(session, form_options: &#123;&#125;) # :doc: # ... raw_token = if per_form_csrf_tokens &amp;&amp; action &amp;&amp; method # ... else real_csrf_token(session) end one_time_pad = SecureRandom.random_bytes(AUTHENTICITY_TOKEN_LENGTH) encrypted_csrf_token = xor_byte_strings(one_time_pad, raw_token) masked_token = one_time_pad + encrypted_csrf_token Base64.strict_encode64(masked_token)end Embeded into form12345678def csrf_meta_tags if protect_against_forgery? [ tag("meta", name: "csrf-param", content: request_forgery_protection_token), tag("meta", name: "csrf-token", content: form_authenticity_token) ].join("\n").html_safe endend then you’ll see: In the post params, get authenticity_token &amp; decryption token and verifyGet masked_token1masked_token = Base64.strict_decode64(encoded_masked_token) Get unmasked_token12345def unmask_token(masked_token) # :doc: one_time_pad = masked_token[0...AUTHENTICITY_TOKEN_LENGTH] encrypted_csrf_token = masked_token[AUTHENTICITY_TOKEN_LENGTH..-1] xor_byte_strings(one_time_pad, encrypted_csrf_token)end Verify123def compare_with_real_token(token, session) # :doc: ActiveSupport::SecurityUtils.secure_compare(token, real_csrf_token(session))end]]></content>
      <categories>
        <category>ROR</category>
      </categories>
      <tags>
        <tag>CSRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSRF (Cross-site request forgery)]]></title>
    <url>%2F2018%2F07%2F24%2Fsecurity-CSRF%2F</url>
    <content type="text"><![CDATA[XSS 利用的是用户对指定网站的信任，CSRF 利用的是网站对用户网页浏览器的信任 简单点说，CSRF 就是利用用户的登录态发起恶意请求 如何攻击假设网站中有一个通过 Get 请求提交用户评论的接口，那么攻击者就可以在钓鱼网站中加入一个图片，图片的地址就是评论接口1&lt;img src=&quot;http://www.domain.com/xxx?comment=&apos;attack&apos;&quot;/&gt; 如果接口是 Post 提交的，就相对麻烦点，需要用表单来提交接口123&lt;form action=&quot;http://www.domain.com/xxx&quot; id=&quot;CSRF&quot; method=&quot;post&quot;&gt; &lt;input name=&quot;comment&quot; value=&quot;attack&quot; type=&quot;hidden&quot;&gt;&lt;/form&gt; 如何防御验证 HTTP Referer 字段根据 HTTP 协议，在 HTTP 头中有一个字段叫 Referer，它记录了该 HTTP 请求的来源地址。在通常情况下，访问一个安全受限页面的请求来自于同一个网站，比如需要访问 http://bank.example/withdraw?account=bob&amp;amount=1000000&amp;for=Mallory，用户必须先登陆 bank.example，然后通过点击页面上的按钮来触发转账事件。因此，要防御 CSRF 攻击，网站只需要对于每一个转账请求验证其 Referer 值，如果是以 bank.example 开头的域名，则说明该请求是来自银行网站自己的请求，是合法的。如果 Referer 是其他网站的话，则有可能是黑客的 CSRF 攻击，拒绝该请求。这种方法的显而易见的好处就是简单易行，网站的普通开发人员不需要操心 CSRF 的漏洞，只需要在最后给所有安全敏感的请求统一增加一个拦截器来检查 Referer 的值就可以。然而，这种方法并非万无一失。Referer 的值是由浏览器提供的，虽然 HTTP 协议上有明确的要求，但是每个浏览器对于 Referer 的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用验证 Referer 值的方法，就是把安全性都依赖于第三方（即浏览器）来保障，从理论上来讲，这样并不安全。事实上，对于某些浏览器，比如IE6 或 FF2，目前已经有一些方法可以篡改 Referer 值。如果 网站支持IE6 浏览器，黑客完全可以把用户浏览器的 Referer 值设为以 bank.example 域名开头的地址，这样就可以通过验证，从而进行 CSRF 攻击。即便是使用最新的浏览器，黑客无法篡改 Referer 值，这种方法仍然有问题。因为 Referer 值会记录下用户的访问来源，有些用户认为这样会侵犯到他们自己的隐私权，特别是有些组织担心 Referer 值会把组织内网中的某些信息泄露到外网中。因此，用户自己可以设置浏览器使其在发送请求时不再提供 Referer。当他们正常访问银行网站时，网站会因为请求没有 Referer 值而认为是 CSRF 攻击，拒绝合法用户的访问。 在请求地址中添加 token 并验证CSRF 攻击之所以能够成功，是因为黑客可以完全伪造用户的请求，该请求中所有的用户验证信息都是存在于 cookie 中，因此黑客可以在不知道这些验证信息的情况下直接利用用户自己的 cookie 来通过安全验证。要抵御 CSRF，关键在于在请求中放入黑客所不能伪造的信息，并且该信息不存在于 cookie 之中。可以在 HTTP 请求中以参数的形式加入一个随机产生的 token，并在服务器端建立一个拦截器来验证这个 token，如果请求中没有 token 或者 token 内容不正确，则认为可能是 CSRF 攻击而拒绝该请求。这种方法要比检查 Referer 要安全一些，token 可以在用户登陆后产生并放于 session 之中，然后在每次请求时把 token 从 session 中拿出，与请求中的 token 进行比对，但这种方法的难点在于如何把 token 以参数的形式加入请求。对于 GET 请求，token 将附在请求地址之后，这样 URL 就变成 http://url?csrftoken=tokenvalue。 而对于 POST 请求来说，要在 form 的最后加上 ，这样就把 token 以参数的形式加入请求了。但是，在一个网站中，可以接受请求的地方非常多，要对于每一个请求都加上 token 是很麻烦的，并且很容易漏掉，通常使用的方法就是在每次页面加载时，使用 javascript 遍历整个 dom 树，对于 dom 中所有的 a 和 form 标签后加入 token。这样可以解决大部分的请求，但是对于在页面加载之后动态生成的 html 代码，这种方法就没有作用，还需要程序员在编码时手动添加 token。该方法还有一个缺点是难以保证 token 本身的安全。特别是在一些论坛之类支持用户自己发表内容的网站，黑客可以在上面发布自己个人网站的地址。由于系统也会在这个地址后面加上 token，黑客可以在自己的网站上得到这个 token，并马上就可以发动 CSRF 攻击。为了避免这一点，系统可以在添加 token 的时候增加一个判断，如果这个链接是链到自己本站的，就在后面添加 token，如果是通向外网则不加。不过，即使这个 csrftoken 不以参数的形式附加在请求之中，黑客的网站也同样可以通过 Referer 来得到这个 token 值以发动 CSRF 攻击。这也是一些用户喜欢手动关闭浏览器 Referer 功能的原因。 在 HTTP 头中自定义属性并验证这种方法也是使用 token 并进行验证，和上一种方法不同的是，这里并不是把 token 以参数的形式置于 HTTP 请求之中，而是把它放到 HTTP 头中自定义的属性里。通过 XMLHttpRequest 这个类，可以一次性给所有该类请求加上 csrftoken 这个 HTTP 头属性，并把 token 值放入其中。这样解决了上种方法在请求中加入 token 的不便，同时，通过 XMLHttpRequest 请求的地址不会被记录到浏览器的地址栏，也不用担心 token 会透过 Referer 泄露到其他网站中去。然而这种方法的局限性非常大。XMLHttpRequest 请求通常用于 Ajax 方法中对于页面局部的异步刷新，并非所有的请求都适合用这个类来发起，而且通过该类请求得到的页面不能被浏览器所记录下，从而进行前进，后退，刷新，收藏等操作，给用户带来不便。另外，对于没有进行 CSRF 防护的遗留系统来说，要采用这种方法来进行防护，要把所有请求都改为 XMLHttpRequest 请求，这样几乎是要重写整个网站，这代价无疑是不能接受的。]]></content>
      <categories>
        <category>Security</category>
      </categories>
      <tags>
        <tag>CSRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器端缓存]]></title>
    <url>%2F2018%2F07%2F24%2Fperformance-brower-cache%2F</url>
    <content type="text"><![CDATA[在请求一个静态文件的时候（图片，css，js）等，这些文件的特点是文件不经常变化，将这些不经常变化的文件存储起来，对客户端来说是一个优化用户浏览体验的方法。那么这个就是客户端缓存的意义了 通常浏览器缓存策略分为两种：强缓存和协商缓存 强缓存实现强缓存可以通过两种响应头实现：Expires 和 Cache-Control 。强缓存表示在缓存期间不需要请求，直接从缓存拿，state code 为 2001Expires: Wed, 22 Oct 2018 08:41:00 GMT Expires 是 HTTP / 1.0 的产物，表示资源会在 Wed, 22 Oct 2018 08:41:00 GMT 后过期，需要再次请求。并且 Expires 受限于本地时间，如果修改了本地时间，可能会造成缓存失效。1Cache-control: max-age=30 Cache-Control 出现于 HTTP / 1.1，优先级高于 Expires 。该属性表示资源会在 30 秒后过期，需要再次请求 协商缓存如果缓存过期了，我们就可以使用协商缓存来解决问题。协商缓存需要请求，如果缓存有效会返回 304。协商缓存需要客户端和服务端共同实现，和强缓存一样，也有两种实现方式。 Last-Modified 和 If-Modified-Since客户端第一次访问资源的时候，服务端返回资源内容的同时返回了Last-Modifed:Wed, 07 Aug 2013 15:32:18 GMT 服务端在告诉客户端：你获取的这个文件我最后的修改时间是Wed, 07 Aug 2013 15:32:18 GMT 。浏览器在获取这个文件存到缓存中的时候，给缓存中的文件同时记录上这个最后修改时间。第二次访问的时候, 那么服务端访问资源的时候会带上If-Modify-since:Wed, 07 Aug 2013 15:32:18 GMT 客户端询问服务端：喂，我需要的这个资源其实我这边已经有缓存了，我的缓存文件的最后修改时间是这个，如果你那边的资源在这个时间以后没有修改的话，你就告诉我一下就好了，不需要返回实际的资源内容。反之，要是你有修改的话，你就把文件内容返回给我吧 服务端回应说：哦。行为是看下资源是否在这个时间后没有修改过，如果没有修改返回个304告诉客户端，我没有修改过。如果有变化了，我就返回200，并且带上资源内容 需要注意的是如果在本地打开缓存文件，就会造成 Last-Modified 被修改，所以在 HTTP / 1.1 出现了 ETag HeadingETag 和 If-None-Match第一次客户端访问资源的时候，服务端返回资源内容的同时返回了ETag：1234，告诉客户端：这个文件的标签是1234，我如果修改了我这边的资源的话，这个标签就会不一样了。第二次客户端访问资源的时候，由于缓存中已经有了Etag为1234的资源，客户端要去服务端查询的是这个资源有木有过期呢？所以带上了If-None-Match: 1234。告诉服务端：如果你那边的资源还是1234标签的资源，你就返回304告诉我，不需要返回资源内容了。如果不是的话，你再返回资源内容给我就行了。服务端就比较下Etag来看是返回304还是200。所以，ETag 类似于文件指纹，If-None-Match 会将当前 ETag 发送给服务器，询问该资源 ETag 是否变动，有变动的话就将新的资源发送回来。并且 ETag 优先级比 Last-Modified 高 选择合适的缓存策略对于大部分的场景都可以使用强缓存配合协商缓存解决，但是在一些特殊的地方可能需要选择特殊的缓存策略 对于某些不需要缓存的资源，可以使用 Cache-control: no-store ，表示该资源不需要缓存 对于频繁变动的资源，可以使用 Cache-Control: no-cache 并配合 ETag 使用，表示该资源已被缓存，但是每次都会发送请求询问资源是否更新 对于代码文件来说，通常使用 Cache-Control: max-age=31536000 并配合策略缓存使用，然后对文件进行指纹处理，一旦文件名变动就会立刻下载新的文件 浏览器刷新浏览器第一次访问，获取资源内容和cache-control: max-age:600，Last_Modify: Wed, 10 Aug 2013 15:32:18 GMT于是浏览器把资源文件放到缓存中，并且决定下次使用的时候直接去缓存中取了 浏览器中写地址，回车浏览器发现缓存中有这个文件了，好了，就不发送任何请求了，直接去缓存中获取展现。（最快） 按下F5刷新F5就是告诉浏览器，别偷懒，好歹去服务器看看这个文件是否有过期了。于是浏览器就胆胆襟襟的发送一个请求带上If-Modify-since：Wed, 10 Aug 2013 15:32:18 GMT然后服务器发现：诶，这个文件我在这个时间后还没修改过，不需要给你任何信息了，返回304就行了。于是浏览器获取到304后就去缓存中欢欢喜喜获取资源了 Ctrl+F5这个可是要命了，告诉浏览器，你先把你缓存中的这个文件给我删了，然后再去服务器请求个完整的资源文件下来。于是客户端就完成了强行更新的操作… Hint对于静态文件，例如：CSS、图片，服务器会自动完成 Last Modified 和 If Modified Since 的比较，完成缓存或者更新]]></content>
      <categories>
        <category>Frontend Performance</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[将CSS文件放在顶部，将Scripts放在底部]]></title>
    <url>%2F2018%2F07%2F23%2Fperformance-css-script%2F</url>
    <content type="text"><![CDATA[将CSS文件放在顶部简介在web页面设计中，一般在HTML中不直接写样式，而是通过link标签引用一个CSS文件在下载页面过程中，document最早开始下载，然后浏览器解析document，下载相关的css、js、图片、字体、视频等资源css文件放置在head中和放在body底部，对css的下载时间不会有影响，但是对页面的呈现有着非常大的影响，与用户的体验密切相关 CSS文件放置在顶部的原理CSS文件放在顶部一方面是因为放置顺序决定了下载的优先级，更关键的是浏览器的渲染机制最理想的情况，我们希望浏览器逐渐的渲染下载好的CSS，将页面逐渐的展现给用户。但是浏览器为了避免样式变化时重新渲染绘制页面元素，会阻塞内容逐步呈现，浏览器等待所有样式加载完成之后才一次性渲染呈现页面如此，CSS文件如果放置底部，浏览器阻止内容逐步呈现，浏览器在等待最后一个CSS文件下载完成的过程中，就出现了“白屏”（新打开连接时为白屏，尔后先出现文字，图片，样式最后出现）这点非常严重，因为在网速非常慢的情况下，css下载时间比较长，这样就给用户带来“白屏”的时间自然也就很长了，用户体验非常差 将Scripts放在底部原因由于下载script会阻塞并行下载，也就是下载script就下载不了其他的资源所以通常将script放到底部 defer 属性 和 async属性 async是异步执行，表示下载完js马上异步执行js defer表示延迟执行，需要等页面资源下载完成后执行 通常还可以再加上一个defer属性执行 JS 代码过长会卡住渲染，对于需要很多时间计算的代码可以考虑使用 WebworkerWebworker 可以让我们另开一个线程执行脚本而不影响渲染]]></content>
      <categories>
        <category>Frontend Performance</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[浏览器中的Event loop]]></title>
    <url>%2F2018%2F07%2F23%2Fbrowser-event-loop%2F</url>
    <content type="text"><![CDATA[众所周知 JS 是门非阻塞单线程语言，因为在最初 JS 就是为了和浏览器交互而诞生的。如果 JS 是门多线程的语言话，我们在多个线程中处理 DOM 就可能会发生问题（一个线程中新加节点，另一个线程中删除节点），当然可以引入读写锁解决这个问题 执行过程JS 在执行的过程中会产生执行环境，这些执行环境会被顺序的加入到执行栈中。如果遇到异步的代码，会被挂起并加入到 Task（有多种 task） 队列中。一旦执行栈为空，Event Loop 就会从 Task 队列中拿出需要执行的代码并放入执行栈中执行，所以本质上来说 JS 中的异步还是同步行为1234567console.log('script start');setTimeout(function() &#123; console.log('setTimeout');&#125;, 0);console.log('script end');以上代码虽然 setTimeout 延时为 0，其实还是异步。这是因为 HTML5 标准规定这个函数第二个参数不得小于 4 毫秒，不足会自动增加。所以 setTimeout还是会在 script end 之后打印。 微任务（microtask） 和 宏任务（macrotask）不同的任务源会被分配到不同的 Task 队列中，任务源可以分为 微任务（microtask） 和 宏任务（macrotask）。在 ES6 规范中，microtask 称为 jobs，macrotask 称为 task1234567891011121314151617console.log('script start');setTimeout(function() &#123; console.log('setTimeout');&#125;, 0);new Promise((resolve) =&gt; &#123; console.log('Promise') resolve()&#125;).then(function() &#123; console.log('promise1');&#125;).then(function() &#123; console.log('promise2');&#125;);console.log('script end');// script start =&gt; Promise =&gt; script end =&gt; promise1 =&gt; promise2 =&gt; setTimeout以上代码虽然 setTimeout 写在 Promise 之前，但是因为 Promise 属于微任务而 setTimeout 属于宏任务，所以会有以上的打印。 微任务包括：process.nextTick ，promise ，Object.observe ，MutationObserver 宏任务包括：script ， setTimeout ，setInterval ，setImmediate ，I/O ，UI rendering 很多人有个误区，认为微任务快于宏任务，其实是错误的。因为宏任务中包括了 script ，浏览器会先执行一个宏任务，接下来有异步代码的话就先执行微任务 总结正确的一次 Event loop 顺序是这样的： 执行同步代码，这属于宏任务 执行栈为空，查询是否有微任务需要执行 执行所有微任务 必要的话渲染 UI 然后开始下一轮 Event loop，执行宏任务中的异步代码 通过上述的 Event loop 顺序可知，如果宏任务中的异步代码有大量的计算并且需要操作 DOM 的话，为了更快的 界面响应，我们可以把操作 DOM 放入微任务中]]></content>
      <categories>
        <category>browser</category>
      </categories>
      <tags>
        <tag>Event loop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器中的Cookie]]></title>
    <url>%2F2018%2F07%2F23%2Fbrowser-cookie%2F</url>
    <content type="text"><![CDATA[cookie 路径cookie 一般都是由于用户访问页面而被创建的，可是并不是只有在创建 cookie 的页面才可以访问这个 cookie默认情况下，只有与创建 cookie 的页面在同一个目录或子目录下的网页才可以访问，这个是因为安全方面的考虑所以不是所有页面都可以随意访问其他页面创建的 cookie example在 “http://www.cnblogs.com/Darren_code/&quot; 这个页面创建一个cookie在”http://www.cnblogs.com/Darren_code/archive/2011/11/07/Cookie.html&quot;这个页面默认就能取到cookie信息可在默认情况下， “http://www.cnblogs.com&quot;或者 “http://www.cnblogs.com/xxxx/&quot; 就不可以访问这个 cookie那么如何让这个 cookie 能被其他目录或者父级的目录访问类，通过设置 cookie 的路径就可以实现12document.cookie = "name=value;path=path"document.cookie = "name=value;expires=date;path=path"最常用的例子就是让 cookie 在根目录下,这样不管是哪个子页面创建的 cookie，所有的页面都可以访问到了:1document.cookie = "name=Darren;path=/" cookie 域路径能解决在同一个域下访问 cookie 的问题，咱们接着说 cookie 实现同域之间访问的问题例如 “www.qq.com&quot; 与 “sports.qq.com” 公用一个关联的域名”qq.com”，我们如果想让 “sports.qq.com” 下的cookie被 “www.qq.com&quot; 访问，我们就需要用到 cookie 的domain属性，并且需要把path属性设置为 “/“1document.cookie = "username=Darren;path=/;domain=qq.com" 发请求带上 cookie以下两个条件缺一不可 Request 需设置 withCredentials 为 true1234567891011var invocation = new XMLHttpRequest();var url = 'http://bar.other/resources/credentialed-content/'; function callOtherDomain()&#123; if(invocation) &#123; invocation.open('GET', url, true); invocation.withCredentials = true; invocation.onreadystatechange = handler; invocation.send(); &#125;&#125; Response 需设置 Access-Control-Allow-Credentials 为 true123456789101112131415HTTP/1.1 200 OKDate: Mon, 01 Dec 2008 01:34:52 GMTServer: Apache/2.0.61 (Unix) PHP/4.4.7 mod_ssl/2.0.61 OpenSSL/0.9.7e mod_fastcgi/2.4.2 DAV/2 SVN/1.4.2X-Powered-By: PHP/5.2.6Access-Control-Allow-Origin: http://foo.exampleAccess-Control-Allow-Credentials: trueCache-Control: no-cachePragma: no-cacheSet-Cookie: pageAccess=3; expires=Wed, 31-Dec-2008 01:34:53 GMTVary: Accept-Encoding, OriginContent-Encoding: gzipContent-Length: 106Keep-Alive: timeout=2, max=100Connection: Keep-AliveContent-Type: text/plain 其他注意 如果设置Access-Control-Allow-Origin为*，请求将不会带上cookie 请设置好http-only，这样浏览器端就不能通过 JS 访问 Cookie，减少 XSS 攻击 属性 作用 value 如果用于保存用户登录态，应该将该值加密，不能使用明文的用户标识 http-only 不能通过 JS 访问 Cookie，减少 XSS 攻击 secure 只能在协议为 HTTPS 的请求中携带 same-site 规定浏览器不能在跨域请求中携带 Cookie，减少 CSRF 攻击]]></content>
      <categories>
        <category>browser</category>
      </categories>
      <tags>
        <tag>cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器跨域]]></title>
    <url>%2F2018%2F07%2F23%2Fbrowser-CORS%2F</url>
    <content type="text"><![CDATA[因为浏览器出于安全考虑，有同源策略。也就是说，如果协议、域名或者端口有一个不同就是跨域，Ajax 请求会失败。我们可以通过以下几种常用方法解决跨域的问题 JSONPJSONP 的原理很简单，就是利用 &lt;script&gt; 标签没有跨域限制的漏洞通过 &lt;script&gt;标签指向一个需要访问的地址并提供一个回调函数来接收数据当需要通讯时123456&lt;script src="http://domain/api?param1=a&amp;param2=b&amp;callback=jsonp"&gt;&lt;/script&gt;&lt;script&gt; function jsonp(data) &#123; console.log(data) &#125;&lt;/script&gt;JSONP 使用简单且兼容性不错，但是只限于 get 请求。在开发中可能会遇到多个 JSONP 请求的回调函数名是相同的，这时候就需要自己封装一个 JSONP，以下是简单实现1234567891011121314151617function jsonp(url, jsonpCallback, success) &#123; let script = document.createElement("script"); script.src = url; script.async = true; script.type = "text/javascript"; window[jsonpCallback] = function(data) &#123; success &amp; success(data); &#125;; document.body.appendChild(script);&#125;jsonp( "http://xxx", "callback", function(value) &#123; console.log(value); &#125;); HTTP访问控制（CORS）MDNCORS需要浏览器和后端同时支持浏览器会自动进行 CORS 通信，实现CORS通信的关键是后端。只要后端实现了 CORS，就实现了跨域。服务端设置 Access-Control-Allow-Origin 就可以开启 CORS。 该属性表示哪些域名可以访问资源，如果设置通配符则表示所有网站都可以访问资源。 预检请求(Preflighted requests CORS)client通过options请求 知道server接受哪些method、header等，来判断真正要发出的请求是否是可接受的 触发条件当请求满足下述任一条件时，即应首先发送预检请求: 使用了下面任一HTTP方法： PUT DELETE CONNECT OPTIONS TRACE PATCH 人为设置了对 CORS 安全的首部字段集合之外的其他首部字段。该集合为 Accept Accept-Language Content-Language Content-Type (but note the additional requirements below) DPR Downlink Save-Data Viewport-Width Width Content-Type 的值不属于下列之一: application/x-www-form-urlencoded multipart/form-data text/plain example Server side code1234567891011app.all('*', function (req, res, next) &#123; // handle all request contain Preflight request and set CORS header res.header('Access-Control-Allow-Origin', req.headers.origin); res.header('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS'); res.header('Access-Control-Allow-Headers', 'Content-Type, Authorization, Origin, X-Requested-With, Accept'); res.header('Access-Control-Allow-Credentials', true); if (req.method === "OPTIONS") &#123;. // handle Preflight request and send res with 200 return res.sendStatus(200); &#125; else &#123; next() // pass control to the next handler &#125;&#125;); CORS规则Request with credential1Origin: http://foo.example Response123Access-Control-Allow-Origin: http://foo.exampleAccess-Control-Allow-Method: POST, GET, OPTIONSAccess-Control-Allow-Credentials: true]]></content>
      <categories>
        <category>browser</category>
      </categories>
      <tags>
        <tag>CORS</tag>
        <tag>JSONP</tag>
        <tag>OPTIONS</tag>
        <tag>Origin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浏览器事件机制]]></title>
    <url>%2F2018%2F07%2F23%2FJS-event%2F</url>
    <content type="text"><![CDATA[事件触发三阶段 document往事件触发处传播，遇到注册的捕获事件会触发 传播到事件触发处时触发注册的事件 从事件触发处往 document 传播，遇到注册的冒泡事件会触发 事件触发一般来说会按照上面的顺序进行，但是也有特例，如果给一个目标节点同时注册冒泡和捕获事件，事件触发会按照注册的顺序执行1234567// 以下会先打印冒泡然后是捕获node.addEventListener('click',(event) =&gt;&#123; console.log('冒泡')&#125;,false);node.addEventListener('click',(event) =&gt;&#123; console.log('捕获 ')&#125;,true) 注册事件通常我们使用 addEventListener 注册事件，该函数的第三个参数可以是布尔值，也可以是对象。对于布尔值 useCapture 参数来说，该参数默认值为 false 。useCapture 决定了注册的事件是捕获事件还是冒泡事件。对于对象参数来说，可以使用以下几个属性: capture，布尔值，和 useCapture 作用一样 once，布尔值，值为 true 表示该回调只会调用一次，调用后会移除监听 passive，布尔值，表示永远不会调用 preventDefault 阻止冒泡 event.stopPropagation(): 事件处理过程中，阻止了事件冒泡，但不会阻击默认行为 return false: 事件处理过程中，阻止了事件冒泡，也阻止了默认行为 event.preventDefault() 阻止了默认行为，但不阻止冒泡 事件代理如果一个节点中的子节点是动态生成的，那么子节点需要注册事件的话应该注册在父节点上12345678910111213&lt;ul id="ul"&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;li&gt;3&lt;/li&gt; &lt;li&gt;4&lt;/li&gt; &lt;li&gt;5&lt;/li&gt;&lt;/ul&gt;&lt;script&gt; let ul = document.querySelector('##ul') ul.addEventListener('click', (event) =&gt; &#123; console.log(event.target); &#125;)&lt;/script&gt;事件代理的方式相对于直接给目标注册事件来说，有以下优点: 节省内存 不需要给子节点注销事件]]></content>
      <categories>
        <category>browser</category>
      </categories>
      <tags>
        <tag>event</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES6 模块与 CommonJS 模块的差异]]></title>
    <url>%2F2018%2F07%2F23%2FJS-module%2F</url>
    <content type="text"><![CDATA[CommonJS模块输出的是一个值的拷贝，ES6 模块输出的是值的引用 CommonJS模块是运行时加载，ES6 模块是编译时输出接口 ES6在有 Babel 的情况下，我们可以直接使用 ES6 的模块化12345678export var firstName = ‘Michael’ === var firstName = 'Michael’; export &#123;firstName&#125;;export function v1() &#123; &#125;; === function v1() &#123; &#125;; export &#123;v1&#125;;import &#123;firstName, lastName, year&#125; from './profile’;import * as circle from './circle’;export default function () &#123; console.log('foo'); &#125;import customName from './export-default’; CommonJSCommonJs 是 Node 独有的规范，浏览器中使用就需要用到Browserify解析了。 每个模块内部，module变量代表当前模块。 这个变量是一个对象，它的exports属性（即module.exports）是对外的接口。加载某个模块，其实是加载该模块的module.exports`属性。1234567891011var x = 5;var addX = function (value) &#123; return value + x;&#125;;module.exports.x = x;module.exports.addX = addX;var example = require('./example.js');console.log(example.x); // 5console.log(example.addX(1)); // 6]]></content>
      <categories>
        <category>JS</category>
      </categories>
      <tags>
        <tag>ES6</tag>
        <tag>CommonJS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS closure]]></title>
    <url>%2F2018%2F07%2F23%2FJS-closure%2F</url>
    <content type="text"><![CDATA[定义在作用域链上的对象访问只能向上，内部作用域能够访问外部作用域的变量，但是外部却无法向内部访问所以在JS中，实现外部作用域 访问 内部作用域中变量的方法叫做闭包，这得益于高阶函数的特性：函数可以作为参数或者返回值12345678function A() &#123; let a = 1 function B() &#123; console.log(a) &#125; return B&#125;A()() // 1 经典面试题12345for ( var i=1; i&lt;=5; i++) &#123; setTimeout( function timer() &#123; console.log( i ); &#125;, i*1000 );&#125; 首先因为 setTimeout 是个异步函数，所有会先把循环全部执行完毕，这时候 i 就是 6 了，所以会输出一堆 6使用闭包解决1234567for (var i = 1; i &lt;= 5; i++) &#123; (function(j) &#123; setTimeout(function timer() &#123; console.log(j); &#125;, j * 1000); &#125;)(i);&#125;]]></content>
      <categories>
        <category>JS</category>
      </categories>
      <tags>
        <tag>closure</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS this]]></title>
    <url>%2F2018%2F07%2F23%2FJS-this%2F</url>
    <content type="text"><![CDATA[JS（ES5）里面有三种函数调用形式 func(p1, p2) obj.child.method(p1, p2) func.call(context, p1, p2) 一般，初学者都知道前两种形式，而且认为前两种形式「优于」第三种形式但是，第三种调用形式，才是正常调用形式1func.call(context, p1, p2) 其他两种都是语法糖，可以等价地变为 call 形式12345func(p1, p2) 等价于func.call(undefined, p1, p2)obj.child.method(p1, p2) 等价于obj.child.method.call(obj.child, p1, p2) 至此我们的函数调用只有一种形式：1func.call(context, p1, p2) this是什么this，就是上面代码中的 contextthis 是你 call 一个函数时传的 context，由于你从来不用 call 形式的函数调用，所以你一直不知道 普通函数中的this: this总是代表它的直接调用者, 例如 obj.func ,那么func中的this就是obj 在默认情况(非严格模式下,未使用 ‘use strict’),没找到直接调用者,则this指的是 window 在严格模式下,没有直接调用者的函数中的this是 undefined 使用call,apply,bind(ES5新增)绑定的,this指的是 绑定的对象 箭头函数中的this默认指向在定义它时,它所处的对象,而不是执行时的对象, 定义它的时候,可能环境是window12345678function a() &#123; return () =&gt; &#123; return () =&gt; &#123; console.log(this) &#125; &#125;&#125;console.log(a()()()) //window箭头函数其实是没有 this 的，这个函数中的 this 只取决于他外面的第一个不是箭头函数的函数的 this。在这个例子中，因为调用 a 符合前面代码中的第一个情况，所以 this 是 window。并且 this 一旦绑定了上下文，就不会被任何代码改变]]></content>
      <categories>
        <category>JS</category>
      </categories>
      <tags>
        <tag>this</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS 原型]]></title>
    <url>%2F2018%2F07%2F23%2Fjs-prototype%2F</url>
    <content type="text"><![CDATA[prototype这是一个显式原型属性，只有函数才拥有该属性prototype 一般可读可写 prototype 如何产生的当我们声明一个函数时，这个属性就被自动创建了1function Foo() &#123;&#125; 并且这个属性的值是一个对象（也就是原型），只有一个属性 constructorconstructor 对应着构造函数，也就是 Foo1Foo.prototype.constructor === Foo //true constructorconstructor是一个公有且不可枚举的属性。一旦我们改变了函数的 prototype ，那么新对象就没有这个属性了（当然可以通过原型链取到 constructor）那么你肯定也有一个疑问，这个属性到底有什么用呢？其实这个属性可以说是一个历史遗留问题，在大部分情况下是没用的，在我的理解里，我认为他有两个作用： 让实例对象知道是什么函数构造了它(obj.__proto__.constructor) 如果想给某些类库中的构造函数增加一些自定义的方法，就可以通过 xx.constructor.method 来扩展 __proto__这是每个对象都有的隐式原型属性，指向了创建该对象的构造函数的原型。其实这个属性指向了 [[prototype]]，但是 [[prototype]] 是内部属性，我们并不能访问到，所以使用 __proto__ 来访问。一般只读因为在 JS 中是没有类的概念的，为了实现类似继承的方式，通过 __proto__将对象和原型联系起来组成原型链，得以让对象可以访问到不属于自己的属性。 实例对象的 __proto__ 如何产生的当我们使用 new 操作符时，生成的实例对象拥有了 __proto__属性。 new 的过程 新生成了一个对象 链接到原型 绑定 this 返回新对象 在调用 new 的过程中会发生以上四件事情，我们也可以试着来自己实现一个 new123456789101112function create() &#123; // 创建一个空的对象 let obj = new Object() // 获得构造函数 let Con = [].shift.call(arguments) // 链接到原型 obj.__proto__ = Con.prototype // 绑定 this，执行构造函数 let result = Con.apply(obj, arguments) // 确保 new 出来的是个对象 return typeof result === 'object' ? result : obj&#125; 判断 一个 对象a是不是类b的实例a.__proto__ === b.prototype Function.__proto__ === Function.prototype 对于对象来说，xx.__proto__.contrcutor 是该对象的构造函数，但是在图中我们可以发现 Function.__proto__ === Function.prototype，难道这代表着 Function 自己产生了自己?答案肯定是否认的，要说明这个问题我们先从 Object 说起。从图中我们可以发现，所有对象都可以通过原型链最终找到 Object.prototype ，虽然 Object.prototype 也是一个对象，但是这个对象却不是 Object 创造的，而是引擎自己创建了 Object.prototype 。所以可以这样说，所有实例都是对象，但是对象不一定都是实例接下来我们来看 Function.prototype 这个特殊的对象，如果你在浏览器将这个对象打印出来，会发现这个对象其实是一个函数。这个函数也是引擎自己创建的。首先引擎创建了 Object.prototype ，然后创建了 Function.prototype ，并且通过__proto__ 将两者联系了起来现在可以来解释 Function.__proto__ === Function.prototype 这个问题了。因为先有的 Function.prototype 以后才有的 function Function() ，所以也就不存在鸡生蛋蛋生鸡的悖论问题了。对于为什么 Function.__proto__ 会等于 Function.prototype ，个人的理解是：其他所有的构造函数都可以通过原型链找到 Function.prototype ，并且 function Function() 本质也是一个函数，为了不产生混乱就将 function Function() 的 __proto__联系到了 Function.prototype 上。 总结 Object 是所有对象的爸爸，所有对象都可以通过__proto__ 找到它 Function 是所有函数的爸爸，所有函数都可以通过 __proto__ 找到它 Function.prototype 和 Object.prototype 是两个特殊的对象，他们由引擎来创建 除了以上两个特殊对象，其他对象都是通过构造器 new 出来的 函数的 prototype 是一个对象，也就是原型 对象的 __proto__ 指向构造函数的原型， __proto__ 将对象和构造函数的原型连接起来组成了原型链]]></content>
      <categories>
        <category>JS</category>
      </categories>
      <tags>
        <tag>prototype</tag>
        <tag>__proto__</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么scripts, styles, and images不遵循Same-Origin Policy]]></title>
    <url>%2F2018%2F07%2F23%2Ftags-SOP%2F</url>
    <content type="text"><![CDATA[GET 请求没有副作用并且页面不能直接读取结果 Sending a GET request (even with cookies) is not harmful; GET requests are not supposed to have any side-effects.None of these tags allow the calling page to (directly) read responses, so they don’t leak information.Therefore, there is (almost) nothing wrong with allow it. 由于历史原因需要兼容之前的网站 The reason is because of legacy. It was built that way many years ago and if it changes now, too many sites will fail. Plus the security implications are well known, since it has been around for so long. 如果都遵循SOP构建网站过于艰难 In short: it would be much harder to build the Web if everything was subject to SOP]]></content>
      <categories>
        <category>JS</category>
      </categories>
      <tags>
        <tag>SOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端项目理想架构]]></title>
    <url>%2F2018%2F07%2F21%2Ftech-dream%2F</url>
    <content type="text"><![CDATA[易于开发 开发工具是否完善 生态圈是否繁荣 社区是否活跃 易于扩展 增加新功能是否容易 新功能是否会显著增加系统复杂度 易于维护 代码是否容易理解 文档是否健全 易于测试 功能的分层是否清晰 副作用少 尽量使用纯函数 易于构建 使用通用的技术和架构 构建工具的选择]]></content>
      <categories>
        <category>技术构想</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[React-Router]]></title>
    <url>%2F2018%2F07%2F21%2FReact-Router%2F</url>
    <content type="text"><![CDATA[为什么需要react-router 单页应用需要进行页面切换 通过 URL 可以定位到页面 更有语义的组织资源 三种路由实现方式 URL 路径 hash 路由 内存路由 核心API 原理 react-router依赖基础 - historyhistory是一个独立的第三方js库，可以用来兼容在不同浏览器、不同环境下对历史记录的管理，拥有统一的API。具体来说里面的history分为三类: 老浏览器的history: 主要通过hash来实现，对应createHashHistory 高版本浏览器: 通过html5里面的history，对应createBrowserHistory node环境下后端渲染: 主要存储在memeory里面，对应createMemoryHistory 实现方式 createBrowserHistory: 利用HTML5里面的history createHashHistory: 通过hash来存储在不同状态下的history信息 createMemoryHistory: 在内存中进行历史记录的存储 执行URL前进 createBrowserHistory: pushState、replaceState createHashHistory: location.hash=*** location.replace() createMemoryHistory: 在内存中进行历史记录的存储 检测URL回退 createBrowserHistory: popstate createHashHistory: hashchange createMemoryHistory: 因为是在内存中操作，跟浏览器没有关系，不涉及UI层面的事情，所以可以直接进行历史信息的回退 同步每个history对象包含下面的属性： history.length - The number of entries in the history stack history.location - The current location (see below) history.action - The current navigation action (see below) 同时history对象还有个listen方法123456history.listen((location, action) =&gt; &#123; console.log( `The current URL is $&#123;location.pathname&#125;$&#123;location.search&#125;$&#123;location.hash&#125;` ) console.log(`The last navigation action was $&#123;action&#125;`)&#125;)这样一来，就可以根据location的变化来执行对应的action，也就是加载某个路径对应的Component综上，实现URL与UI界面的同步也就转变成location与components之间的同步 具体实现组件层面描述实现过程在react-router中最主要的component是Router RouterContext Link history库起到了中间桥梁的作用 API层面描述实现过程 browserHistory 和 hashHistory hashHistory URL：http://myurl.com/#page/another_page/another_page BrowserHistory URL：http://myurl.com/page/another_page/another_page hashHistory可以兼容低版本浏览器用browserHistory ，在你登录前访问某个url时，server端能拿到完整的url，所以登录后可以帮你重定向到这个url如果用hashHistory server端拿不到#后面的东西所以就不能正确重定向 Browsers do not send the #hash part of URL in any of HTTP requests.Therefore server-side (i.e. NodeJS) would not know what #hash was in the URL when user requested a page.A good example is user trying to load a page that requires a login (via oAuth etc.). Before user is taken to a separate website for authentication, you app’s server-side would tell the authentication vendor what URL redirect user to after a successful login (usually it is to the original URL requested as most websites do this). If you were to use hashHistory - server-side would know only the bits before # symbol and would redirect user to the main page of your app and not a sub-page that user wanted to load.]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>React-Router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Immutability - redux最佳实践]]></title>
    <url>%2F2018%2F07%2F21%2FReact-immutable%2F</url>
    <content type="text"><![CDATA[JavaScript 中的对象一般是可变的（Mutable），因为使用了引用赋值，新的对象简单的引用了原始对象，改变新的对象将影响到原始对象如 foo={a: 1}; bar=foo; bar.a=2 你会发现此时 foo.a 也被改成了 2虽然这样做可以节约内存，但当应用复杂后，这就造成了非常大的隐患，Mutable 带来的优点变得得不偿失为了解决这个问题，一般的做法是使用 shallowCopy（浅拷贝）或 deepCopy（深拷贝）来避免被修改，但这样做造成了 CPU 和内存的浪费 优点 优化性能：改变前的state和改变后的state不是同一个对象，直接可以根据state对象不同来判断state已经变化 易于调试和跟踪：改变前的sate和改变后的state都存在，方便追溯 易于推测：state的变化一定是action引起的，每个action对应一个新的state 操作不可变数据的方法原生写法 immutable.jsImmutable Data 就是一旦创建，就不能再被更改的数据。对 Immutable 对象的任何修改或添加删除操作都会返回一个新的 Immutable 对象。Immutable 实现的原理是 Persistent Data Structure（持久化数据结构），也就是使用旧数据创建新数据时，要保证旧数据同时可用且不变。同时为了避免 deepCopy 把所有节点都复制一遍带来的性能损耗，Immutable 使用了 Structural Sharing（结构共享），即如果对象树中一个节点发生变化，只修改这个节点和受它影响的父节点，其它节点则进行共享 Immutable 降低了 Mutable 带来的复杂度12345function touchAndLog(touchFn) &#123; let data = &#123; key: 'value' &#125;; touchFn(data); console.log(data.key); // 猜猜会打印什么？&#125; 在不查看 touchFn 的代码的情况下，因为不确定它对 data 做了什么，你是不可能知道会打印什么（这不是废话吗）但如果 data 是 Immutable 的呢，你可以很肯定的知道打印的是 value 节省内存Immutable.js 使用了 Structure Sharing 会尽量复用内存，甚至以前使用的对象也可以再次被复用没有被引用的对象会被垃圾回收123456789import &#123; Map&#125; from 'immutable';let a = Map(&#123; select: 'users', filter: Map(&#123; name: 'Cam' &#125;)&#125;)let b = a.set('select', 'people');a === b; // falsea.get('filter') === b.get('filter'); // true上面 a 和 b 共享了没有变化的 filter 节点 Undo/Redo，Copy/Paste，甚至时间旅行这些功能做起来小菜一碟因为每次数据都是不一样的，只要把这些数据放到一个数组里储存起来，想回退到哪里就拿出对应数据即可，很容易开发出撤销重做这种功能 并发安全传统的并发非常难做，因为要处理各种数据不一致问题，因此『聪明人』发明了各种锁来解决。但使用了 Immutable 之后，数据天生是不可变的，并发锁就不需要了。 然而现在并没什么卵用，因为 JavaScript 还是单线程运行的啊。但未来可能会加入，提前解决未来的问题不也挺好吗? 拥抱函数式编程Immutable 本身就是函数式编程中的概念，纯函数式编程比面向对象更适用于前端开发。因为只要输入一致，输出必然一致，这样开发的组件更易于调试和组装 immutability-helper immer]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>immutable-js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React多种方法绑定this]]></title>
    <url>%2F2018%2F07%2F20%2FReact-bind-this%2F</url>
    <content type="text"><![CDATA[React.createClass 自动绑定React 中创建组件的方式已经很多，比较古老的诸如 React.createClass 应该很多人并不陌生。当然，从 React 0.13 开始，可以使用 ES6 Class 代替 React.createClass 了，这应该是今后推荐的方法。 但是需要知道，React.createClass 创建的组件，可以自动绑定 this。也就是说，this 这个关键字会自动绑定在组件实例上面123// This magically works with React.createClass// because `this` is bound for you.onChange = &#123;this.handleChange&#125;当然很遗憾，对于组件的创建，官方已经推荐使用 class 声明组件或使用 functional 无状态组件： Later, classes were added to the language as part of ES2015, so we added the ability to create React components using JavaScript classes. Along with functional components, JavaScript classes are now the preferred way to create components in React. For your existing createClass components, we recommend that you migrate them to JavaScript classes. 我认为，这其实是 React 框架本身的自我完善和对未来的迎合，是框架和语言发展的大势所趋 渲染时绑定通过前文，我们知道最传统的组件创建方式不会有 this 绑定的困扰。接下来，我们假定所有的组件都采取 ES6 classes 方式声明。这种情况下，this 无法自动绑定。一个常见的解决方案便是1onChange = &#123;this.handleChange.bind(this)&#125;这种方法简明扼要，但是有一个潜在的性能问题：当组件每次重新渲染时，都会有一个新的函数创建。OMG! 这听上去貌似是一个很大的问题，但是其实在真正的开发场景中，由此引发的性能问题往往不值一提（除非是大型组件消费类应用或游戏） 箭头函数绑定这种方法其实和第二种类似，拜 ES6 箭头函数所赐，我们可以隐式绑定 this：1onChange = &#123;e =&gt; this.handleChange(e)&#125;当然，也与第二种方法一样，它同样存在潜在的性能问题。下面将要介绍的两种方法，可以有效规避不必要的性能消耗，请继续阅读。 Constructor 内绑定constructor 方法是类的默认方法，通过new命令生成对象实例时，自动调用该方法。 所以我们可以1234constructor(props) &#123; super(props); this.handleChange = this.handleChange.bind(this);&#125;这种方式往往被推荐为“最佳实践”，也是笔者最为常用的方法。 但是就个人习惯而言，我认为与前两种方法相比，constructor 内绑定在可读性和可维护性上也许有些欠缺。 同时，我们知道在 constructor 声明的方法不会存在实例的原型上，而属于实例本身的方法。每个实例都有同样一个 handleChange，这本身也是一种重复和浪费。 Class 属性中使用 = 和箭头函数这个方法依赖于 ES next 的新特性1234handleChange = () =&gt; &#123; // call this function from render // and this.whatever in here works fine.&#125;; 小总结本文在对比 React 绑定 this 的五种方法的同时，也由远及近了解了 javascript 语言的发展：从 ES5 的 bind， 到 ES6 的箭头函数，再到 ES next 对 class 的改进。 React 作为蓬勃发展的框架也同样在与时具进，不断完善，结合语言特性的发展不断调整着自身。 最后，我们通过这张图片来完整回顾 牛逼做法下面代码是我前同事杨峥的骚操作，构造了一个BaseComponent的类，里面的bindMethods方法会将这个类里面所有以 _ 开头的方法给自动绑定this，其他组件直接继承这个BaseComponent就可以自动绑定了12345678910111213141516171819202122232425262728293031323334353637383940import React from 'react';export default class BaseComponent extends React.Component &#123; constructor(props) &#123; super(props); this.state = this.getInitState(); this.bindMethods(); &#125; getInitState() &#123; return &#123;&#125;; &#125; bindMethods() &#123; // only method startwith only one _ will be mounted let props = []; let obj = this; do &#123; let l = Object.getOwnPropertyNames(obj) .concat(Object.getOwnPropertySymbols(obj).map(s =&gt; s.toString())) .sort() .filter((p, i, arr) =&gt; p[0] === '_' &amp;&amp; p[1] !== '_' &amp;&amp; typeof obj[p] === 'function' &amp;&amp; p !== 'constructor' &amp;&amp; props.indexOf(p) === -1 ); props = props.concat(l) &#125; while ( (obj = Object.getPrototypeOf(obj)) &amp;&amp; //walk-up the prototype chain Object.getPrototypeOf(obj) //not the the Object prototype methods (hasOwnProperty, etc...) ) for (let prop of props) &#123; this[prop] = this[prop].bind(this); &#125; &#125;&#125;每每想起骚哥，那种对代码的追求和那股较真的劲儿，让我深刻的认识到一个泥水匠和一个艺术家的区别PS：他们初次review我代码被打回去了10+次 Passing Arguments to Event HandlersInside a loop it is common to want to pass an extra parameter to an event handler. For example, if id is the row ID, either of the following would work12&lt;button onClick=&#123;(e) =&gt; this.deleteRow(id, e)&#125;&gt;Delete Row&lt;/button&gt;&lt;button onClick=&#123;this.deleteRow.bind(this, id)&#125;&gt;Delete Row&lt;/button&gt;The above two lines are equivalent, and use arrow functions and Function.prototype.bind respectivelyIn both cases, the e argument representing the React event will be passed as a second argument after the ID. With an arrow function, we have to pass it explicitly, but with bind any further arguments are automatically forwarded.]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>this</tag>
        <tag>bind</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BFC（Block Formatting Context）]]></title>
    <url>%2F2018%2F07%2F20%2FBFC%2F</url>
    <content type="text"><![CDATA[什么是BFC写CSS样式时，对一个元素设置css,我们首先要知道这个元素是块级元素还是行内元素，而BFC就是用来格式化块级盒子的。 Formatting Context：指页面中一个渲染区域，并且拥有一套渲染规则，它决定了其子元素如何定位，以及与其他元素的相互关系和作用 BFC定义：块级格式化上下文，它是指一个独立的块级渲染区域，只有Block-level Box参与，该区域拥有一套渲染规则来约束块级盒子的布局，且与区域外部无关。 BFC的生成满足下列CSS声明之一的元素便会生成BFC： 根元素或其它包含它的元素 float的值不为none overflow的值不为visible position的值不为static display的值为inline-block、table-cell、table-caption flex boxes BFC的布局规则 内部的元素会在垂直方向一个接一个地排列，可以理解为是BFC中的一个常规流 Box垂直方向的距离由margin决定。属于同一个BFC的两个相邻Box的margin会发生重叠 每个元素的左外边距与包含块的左边界相接触(从左往右，否则相反)，即使存在浮动也是如此，这说明BFC中的子元素不会超出它的包含块 BFC的区域不会与float元素区域重叠 计算BFC的高度时，浮动子元素也参与计算 BFC就是页面上的一个隔离的独立容器，容器里面的子元素不会影响到外面的元素，反之亦然 BFC的应用解决margin重叠问题玩css的朋友都知道margin collapse，也就是相邻的垂直元素同时设置了margin后，实际margin值会塌陷到其中较大的那个值。其根本原理就是它们处于同一个BFC，符合“属于同一个BFC的两个相邻元素的margin会发生重叠”的规则1234567891011121314&lt;style&gt; p &#123; color: #f55; background: #fcc; width: 200px; line-height: 100px; text-align:center; margin: 100px; &#125;&lt;/style&gt;&lt;body&gt; &lt;p&gt;Haha&lt;/p&gt; &lt;p&gt;Hehe&lt;/p&gt;&lt;/body&gt; 两个p之间的距离为100px，发送了margin重叠 Box垂直方向的距离由margin决定。属于同一个BFC的两个相邻Box的margin会发生重叠 我们可以在p外面包裹一层容器，并触发该容器生成一个BFC。那么两个P便不属于同一个BFC，就不会发生margin重叠了。12345678910111213141516171819&lt;style&gt; .wrap &#123; overflow: hidden; &#125; p &#123; color: #f55; background: #fcc; width: 200px; line-height: 100px; text-align:center; margin: 100px; &#125;&lt;/style&gt;&lt;body&gt; &lt;p&gt;Haha&lt;/p&gt; &lt;div class="wrap"&gt; &lt;p&gt;Hehe&lt;/p&gt; &lt;/div&gt;&lt;/body&gt; 自适应双栏布局12345678910111213141516171819202122&lt;style&gt; body &#123; width: 300px; position: relative; &#125; .aside &#123; width: 100px; height: 150px; float: left; background: #f66; &#125; .main &#123; height: 200px; background: #fcc; &#125;&lt;/style&gt;&lt;body&gt; &lt;div class="aside"&gt;&lt;/div&gt; &lt;div class="main"&gt;&lt;/div&gt;&lt;/body&gt; 每个元素的margin box的左边， 与包含块border box的左边相接触(对于从左往右的格式化，否则相反)。即使存在浮动也是如此 因此，虽然存在浮动的元素aslide，但main的左边依然会与包含块的左边相接触。根据BFC布局规则第四条: BFC的区域不会与float box重叠 我们可以通过通过触发main生成BFC， 来实现自适应两栏布局123.main &#123; overflow: hidden;&#125;当触发main生成BFC后，这个新的BFC不会与浮动的aside重叠。因此会根据包含块的宽度，和aside的宽度，自动变窄。效果如下 清除内部浮动12345678910111213141516171819&lt;style&gt; .par &#123; border: 5px solid #fcc; width: 300px; &#125; .child &#123; border: 5px solid #f66; width:100px; height: 100px; float: left; &#125;&lt;/style&gt;&lt;body&gt; &lt;div class="par"&gt; &lt;div class="child"&gt;&lt;/div&gt; &lt;div class="child"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt; 根据BFC布局规则第六条： 计算BFC的高度时，浮动元素也参与计算 为达到清除内部浮动，我们可以触发par生成BFC，那么par在计算高度时，par内部的浮动元素child也会参与计算123.par &#123; overflow: hidden;&#125; 总结其实以上的几个例子都体现了BFC布局规则第五条： BFC就是页面上的一个隔离的独立容器，容器里面的子元素不会影响到外面的元素。反之也如此 因为BFC内部的元素和外部的元素绝对不会互相影响，因此， 当BFC外部存在浮动时，它不应该影响BFC内部Box的布局，BFC会通过变窄，而不与浮动有重叠。同样的，当BFC内部有浮动时，为了不影响外部元素的布局，BFC计算高度时会包括浮动的高度。避免margin重叠也是这样的一个道理]]></content>
      <categories>
        <category>CSS</category>
      </categories>
      <tags>
        <tag>BFC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React 注意事项]]></title>
    <url>%2F2018%2F07%2F20%2FReact-hints%2F</url>
    <content type="text"><![CDATA[用Functional Component 代替 Stateful ComponentStateful Component12345class Avatar extends React.Component &#123; render() &#123; return &lt;img src=&#123;this.props.url&#125; /&gt;; &#125;&#125;Functional Component1234// simplified version of our real componentconst Avatar = (props) =&gt; &#123; return &lt;img src=&#123;props.url&#125; /&gt;;&#125;Functional Component 实际上就是一个JS的function，它返回一些元素但是，你可能会认为Functional Component可能会避开像mounting / unmounting这些生命周期事件，那你就傻逼了下面是React作者的twitter This pattern is designed to encourage the creation of these simple components that should comprise large portions of your apps. In the future, we’ll also be able to make performance optimizations specific to these components by avoiding unnecessary checks and memory allocations. 用调用函数的方式加载Component原文链接123456789101112131415161718192021 ReactDOM.render( &lt;div&gt;- &lt;Avatar url=&#123;avatarUrl&#125; /&gt;+ &#123;Avatar(&#123; url: avatarUrl &#125;)&#125; &lt;div&gt;&#123;commentBody&#125;&lt;/div&gt; &lt;/div&gt;, mountNode ); // Compiled JavaScript ReactDOM.render(React.createElement( 'div', null,- React.createElement(Avatar, &#123; url: avatarUrl &#125;),+ Avatar(&#123; url: avatarUrl &#125;), React.createElement( 'div', null, commentBody ) ), mountNode);像上面代码展示的那样用+的方式（直接调用函数）代替 JSX tags 的方式 来加载Avatar这个Functional Component，我们会省略掉一个React.createElement的调用 和 它里面的所有的React生命周期事件，我们再也不需要等待React Team 去优化Functional Component了。实验证明，使用直接加载Functional Component的方式，会加速45% 阻止冒泡React自己实现了一套时间代理机制叫做SyntheticEvent，一个基于浏览器原生事件的跨浏览器实现。它拥有和浏览器原生事件一样的接口，包括stopPropagation()和preventDefault()，除了那些所有浏览器功能一样的事件而例如jQuery的事件代理是可以在React内部并行的所以当你要阻止一个事件冒泡时，很可能你需要像下面这样写：1234stopPropagation: function(e)&#123; e.stopPropagation(); //阻止React冒泡 e.nativeEvent.stopImmediatePropagation();//阻止原生js冒泡&#125;, 不要忘了React KeyReact will determine whether it is the same component or not based on keyNew component on the same level as old one? Would you kindly change a key? 不要在render里call ActionThe render() function should be pure, meaning that it does not modify component state.If you in render function call Action an return some data to setState,This will cause render a page multiple times or endless-loop. passing the component initial state a prop an anti-pattern这其实是一种props和state混用的情况，不建议在 initial state 根据传入的 props 来赋值当然最好是保证组件stateless React setState setState不会马上改变state，是异步操作 setState总会触发render除非shouldComponentUpdate返回false]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>hints</tag>
        <tag>Functional Component</tag>
        <tag>SyntheticEvent</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redux]]></title>
    <url>%2F2018%2F07%2F19%2FRedux%2F</url>
    <content type="text"><![CDATA[一个JS状态管理框架 不需要redux 用户的使用方式非常简单 用户之间没有协作 不需要与服务器大量交互，也没有使用 WebSocket 视图层（View）只从单一来源获取数据 需要redux 某个组件的状态，需要共享 某个状态需要在任何地方都可以拿到 一个组件需要改变全局状态 一个组件需要改变另一个组件的状态 特性Single Source of Truth 可预测性 纯函数更新 StoreReducer 函数最重要的特征是，它是一个纯函数。也就是说，只要是同样的输入，必定得到同样的输出。纯函数是函数式编程的概念，必须遵守以下一些约束 不得改写参数 不能调用系统 I/O 的API 不能调用Date.now()或者Math.random()等不纯的方法，因为每次会得到不一样的结果 由于 Reducer 是纯函数，就可以保证同样的State，必定得到同样的 View。但也正因为这一点，Reducer 函数里面不能改变 State，必须返回一个全新的对象 StoreStore 就是保存数据的地方，你可以把它看成一个容器。整个应用只能有一个 StoreRedux 提供createStore这个函数，用来生成 Store12import &#123; createStore &#125; from &apos;redux&apos;;const store = createStore(Reducer); store.getState()Store对象包含所有数据。如果想得到某个时点的数据，就要对 Store 生成快照。这种时点的数据集合，就叫做 State。当前时刻的 State，可以通过store.getState()拿到 store.dispatch()store.dispatch()是 View 发出 Action 的唯一方法1234567import &#123; createStore &#125; from &apos;redux&apos;;const store = createStore(fn);store.dispatch(&#123; type: &apos;ADD_TODO&apos;, payload: &apos;Learn Redux&apos;&#125;); 上面代码中，store.dispatch接受一个 Action 对象作为参数，将它发送出去结合 Action Creator，这段代码可以改写如下:1store.dispatch(addTodo(&apos;Learn Redux&apos;)); store.subscribe()Store 允许使用store.subscribe方法设置监听函数，一旦 State发生变化，就自动执行这个函数显然，只要把 View 的更新函数（对于 React 项目，就是组件的render方法或setState方法）放入listen，就会实现 View 的自动渲染 actionState 的变化，会导致 View 的变化。但是，用户接触不到 State，只能接触到 View。所以，State 的变化必须是 View 导致的。Action 就是 View 发出的通知，表示 State 应该要发生变化了Action 是一个对象。其中的type属性是必须的，表示 Action 的名称。其他属性可以自由设置。1234const action = &#123; type: &apos;ADD_TODO&apos;, payload: &apos;Learn Redux&apos;&#125;; 上面代码中，Action 的名称是ADD_TODO，它携带的信息是字符串Learn Redux。可以这样理解，Action 描述当前发生的事情。改变 State 的唯一办法，就是使用 Action。它会运送数据到 Store reducerStore 收到 Action 以后，必须给出一个新的 State，这样 View 才会发生变化。这种 State 的计算过程就叫做 ReducerReducer 是一个函数，它接受 Action 和当前 State 作为参数，返回一个新的 State。1234const reducer = function (state, action) &#123; // ... return new_state;&#125;; bindActionCreators就是将action和dispatch action 结合起来返回一个函数，这个函数实现了两个功能 生成action dispatch这个action 总结首先，用户发出 Action1store.dispatch(action) 然后，Store 自动调用 Reducer，并且传入两个参数：当前 State 和收到的 Action。 Reducer 会返回新的 State1let nextState = todoApp(previousState, action) State 一旦有变化，Store 就会调用监听函数12// 设置监听函数store.subscribe(listener); listener可以通过store.getState()得到当前状态。如果使用的是 React，这时可以触发重新渲染 View1234function listerner() &#123; let newState = store.getState(); component.setState(newState); &#125; example123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566import React from "react";import &#123; createStore, combineReducers, bindActionCreators&#125; from "redux";function run() &#123; // Store initial state const initialState = &#123; count: 0 &#125;; // reducer const counter = (state = initialState, action) =&gt; &#123; switch (action.type) &#123; case "PLUS_ONE": return &#123; count: state.count + 1 &#125;; case "MINUS_ONE": return &#123; count: state.count - 1 &#125;; case "CUSTOM_COUNT": return &#123; count: state.count + action.payload.count &#125;; default: break; &#125; return state; &#125;; const todos = (state = &#123;&#125;) =&gt; state; // Create store const store = createStore( combineReducers(&#123; todos, counter &#125;) ); // Action creator function plusOne() &#123; // action return &#123; type: "PLUS_ONE" &#125;; &#125; function minusOne() &#123; return &#123; type: "MINUS_ONE" &#125;; &#125; function customCount(count) &#123; return &#123; type: "CUSTOM_COUNT", payload: &#123; count &#125; &#125;; &#125; plusOne = bindActionCreators(plusOne, store.dispatch); store.subscribe(() =&gt; console.log(store.getState())); // store.dispatch(plusOne()); plusOne(); store.dispatch(minusOne()); store.dispatch(customCount(5));&#125;export default () =&gt; ( &lt;div&gt; &lt;button onClick=&#123;run&#125;&gt;Run&lt;/button&gt; &lt;p&gt;* 请打开控制台查看运行结果&lt;/p&gt; &lt;/div&gt;);]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>Redux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React-Context]]></title>
    <url>%2F2018%2F07%2F19%2Freact-context%2F</url>
    <content type="text"><![CDATA[在一个典型的 React 应用中，数据是通过 props 属性由上向下（由父及子）的进行传递的，但这对于某些类型的属性而言是极其繁琐的（例如：地区偏好，UI主题），这是应用程序中许多组件都所需要的。 Context 提供了一种在组件之间共享此类值的方式，而不必通过组件树的每个层级显式地传递 props 何时使用 ContextContext 设计目的是为共享那些被认为对于一个组件树而言是“全局”的数据，例如当前认证的用户、主题或首选语言。例如，在下面的代码中，我们通过一个“theme”属性手动调整一个按钮组件的样式：1234567891011121314151617181920function ThemedButton(props) &#123; return &lt;Button theme=&#123;props.theme&#125; /&gt;;&#125;// 中间组件function Toolbar(props) &#123; // Toolbar 组件必须添加一个额外的 theme 属性 // 然后传递它给 ThemedButton 组件 return ( &lt;div&gt; &lt;ThemedButton theme=&#123;props.theme&#125; /&gt; &lt;/div&gt; );&#125;class App extends React.Component &#123; render() &#123; return &lt;Toolbar theme="dark" /&gt;; &#125;&#125;使用 context, 我可以避免通过中间元素传递 props：123456789101112131415161718192021222324252627282930// 创建一个 theme Context, 默认 theme 的值为 lightconst ThemeContext = React.createContext('light');function ThemedButton(props) &#123; // ThemedButton 组件从 context 接收 theme return ( &lt;ThemeContext.Consumer&gt; &#123;theme =&gt; &lt;Button &#123;...props&#125; theme=&#123;theme&#125; /&gt;&#125; &lt;/ThemeContext.Consumer&gt; );&#125;// 中间组件function Toolbar(props) &#123; return ( &lt;div&gt; &lt;ThemedButton /&gt; &lt;/div&gt; );&#125;class App extends React.Component &#123; render() &#123; return ( &lt;ThemeContext.Provider value="dark"&gt; &lt;Toolbar /&gt; &lt;/ThemeContext.Provider&gt; ); &#125;&#125; 改变Context内state的状态，所有的consumer随之更新实现点击切换语言来更新语言 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import React from "react";const enStrings = &#123; submit: "Submit", cancel: "Cancel"&#125;;const cnStrings = &#123; submit: "提交", cancel: "取消"&#125;;const LocaleContext = React.createContext(enStrings);class LocaleProvider extends React.Component &#123; state = &#123; locale: cnStrings &#125;; toggleLocale = () =&gt; &#123; const locale = this.state.locale === enStrings ? cnStrings : enStrings; this.setState(&#123; locale &#125;); &#125;; render() &#123; return ( &lt;LocaleContext.Provider value=&#123;this.state.locale&#125;&gt; &lt;button onClick=&#123;this.toggleLocale&#125;&gt; 切换语言 &lt;/button&gt; &#123;this.props.children&#125; &lt;/LocaleContext.Provider&gt; ); &#125;&#125;class LocaledButtons extends React.Component &#123; render() &#123; return ( &lt;LocaleContext.Consumer&gt; &#123;locale =&gt; ( &lt;div&gt; &lt;button&gt;&#123;locale.cancel&#125;&lt;/button&gt; &amp;nbsp;&lt;button&gt;&#123;locale.submit&#125;&lt;/button&gt; &lt;/div&gt; )&#125; &lt;/LocaleContext.Consumer&gt; ); &#125;&#125;export default () =&gt; ( &lt;div&gt; &lt;LocaleProvider&gt; &lt;div&gt; &lt;br /&gt; &lt;LocaledButtons /&gt; &lt;/div&gt; &lt;/LocaleProvider&gt; &lt;/div&gt;);]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>Context</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React lifecycle v16.3 changes]]></title>
    <url>%2F2018%2F07%2F19%2FReact-lifecycle%2F</url>
    <content type="text"><![CDATA[v16.3之前的lifecycle传统组件生命周期会导致一些不安全的编码实践，他们是： componentWillMount componentWillReceiveProps componentWillUpdate 这些生命周期方法经常被误解和滥用此外，我们预计他们的潜在滥用可能在异步渲染方面有更大的问题。因此，我们将在即将发布的版本中为这些生命周期添加一个“UNSAFE_”前缀 逐渐迁移的计划 16.3：为不安全生命周期引入别名UNSAFE_componentWillMount， UNSAFE_componentWillReceiveProps和UNSAFE_componentWillUpdate。 （旧的生命周期名称和新的别名都可以在此版本中使用。） 未来的16.x版本: 为componentWillMount，componentWillReceiveProps和componentWillUpdate启用弃用警告。 （旧的生命周期名称和新的别名都可以在此版本中使用，但旧名称会记录DEV模式警告。） 17.0: 删除componentWillMount，componentWillReceiveProps和componentWillUpdate。 （从现在开始，只有新的“UNSAFE_”生命周期名称将起作用。） v16.3lifecycle改动 We are adding the following lifecycle aliases: UNSAFE_componentWillMount, UNSAFE_componentWillReceiveProps, and UNSAFE_componentWillUpdate. (Both the old lifecycle names and the new aliases will be supported.) We are introducing two new lifecycles, static getDerivedStateFromProps and getSnapshotBeforeUpdate getDerivedStateFromProps12345class Example extends React.Component &#123; static getDerivedStateFromProps(nextProps, prevState) &#123; // ... &#125;&#125; 新的静态getDerivedStateFromProps生命周期在组件实例化以及接收新props后调用。它可以返回一个对象来更新state，或者返回null来表示新的props不需要任何state更新与componentDidUpdate一起，这个新的生命周期应该覆盖传统componentWillReceiveProps的所有用例 getSnapshotBeforeUpdate12345class Example extends React.Component &#123; getSnapshotBeforeUpdate(prevProps, prevState) &#123; // ... &#125;&#125; 新的getSnapshotBeforeUpdate生命周期在更新之前被调用（例如，在DOM被更新之前）。此生命周期的返回值将作为第三个参数传递给componentDidUpdate。 （这个生命周期不是经常需要的，但可以用于在恢复期间手动保存滚动位置的情况。）与componentDidUpdate一起，这个新的生命周期将覆盖旧版componentWillUpdate的所有用例 Examples初始化状态（Initializing state）这个例子展示了一个调用componentWillMount中带有setState的组件：1234567891011// Beforeclass ExampleComponent extends React.Component &#123; state = &#123;&#125;; componentWillMount() &#123; this.setState(&#123; currentColor: this.props.defaultColor, palette: 'rgb', &#125;); &#125;&#125;这种类型的组件最简单的重构是将状态初始化移动到构造函数或属性初始值设定项，如下所示：1234567// Afterclass ExampleComponent extends React.Component &#123; state = &#123; currentColor: this.props.defaultColor, palette: 'rgb', &#125;;&#125; 获取外部数据(Fetching external data)在componentDidMount中获取外部数据1234567891011121314151617181920212223242526272829// Afterclass ExampleComponent extends React.Component &#123; state = &#123; externalData: null, &#125;; componentDidMount() &#123; this._asyncRequest = asyncLoadData().then( externalData =&gt; &#123; this._asyncRequest = null; this.setState(&#123;externalData&#125;); &#125; ); &#125; componentWillUnmount() &#123; if (this._asyncRequest) &#123; this._asyncRequest.cancel(); &#125; &#125; render() &#123; if (this.state.externalData === null) &#123; // Render loading state ... &#125; else &#123; // Render real UI ... &#125; &#125;&#125; 添加事件监听(Adding event listeners )添加事件监听的推荐方式是使用componentDidMount生命周期12345678910111213141516171819202122232425262728293031323334353637// Afterclass ExampleComponent extends React.Component &#123; state = &#123; subscribedValue: this.props.dataSource.value, &#125;; componentDidMount() &#123; // Event listeners are only safe to add after mount, // So they won't leak if mount is interrupted or errors. this.props.dataSource.subscribe( this.handleSubscriptionChange ); // External values could change between render and mount, // In some cases it may be important to handle this case. if ( this.state.subscribedValue !== this.props.dataSource.value ) &#123; this.setState(&#123; subscribedValue: this.props.dataSource.value, &#125;); &#125; &#125; componentWillUnmount() &#123; this.props.dataSource.unsubscribe( this.handleSubscriptionChange ); &#125; handleSubscriptionChange = dataSource =&gt; &#123; this.setState(&#123; subscribedValue: dataSource.value, &#125;); &#125;;&#125; 基于props更新state以下是使用旧版componentWillReceiveProps生命周期基于新的道具值更新状态的组件示例123456789101112131415// Beforeclass ExampleComponent extends React.Component &#123; state = &#123; isScrollingDown: false, &#125;; componentWillReceiveProps(nextProps) &#123; if (this.props.currentRow !== nextProps.currentRow) &#123; this.setState(&#123; isScrollingDown: nextProps.currentRow &gt; this.props.currentRow, &#125;); &#125; &#125;&#125;尽管上面的代码本身并没有问题，但componentWillReceiveProps生命周期通常会被错误地用于解决问题。因此，该方法将被弃用。从版本16.3开始，更新state以响应props更改的推荐方法是使用新的静态getDerivedStateFromProps生命周期。 （生命周期在组件创建时以及每次收到新道具时调用）：12345678910111213141516171819202122// Afterclass ExampleComponent extends React.Component &#123; // Initialize state in constructor, // Or with a property initializer. state = &#123; isScrollingDown: false, lastRow: null, &#125;; static getDerivedStateFromProps(nextProps, prevState) &#123; if (nextProps.currentRow !== prevState.lastRow) &#123; return &#123; isScrollingDown: nextProps.currentRow &gt; prevState.lastRow, lastRow: nextProps.currentRow, &#125;; &#125; // Return null to indicate no change to state. return null; &#125;&#125; 调用外部回调函数(Invoking external callbacks)下面是一个在内部状态发生变化时调用外部函数的组件示例：1234567891011// Beforeclass ExampleComponent extends React.Component &#123; componentWillUpdate(nextProps, nextState) &#123; if ( this.state.someStatefulValue !== nextState.someStatefulValue ) &#123; nextProps.onChange(nextState.someStatefulValue); &#125; &#125;&#125;在异步模式下使用componentWillUpdate都是不安全的，因为外部回调可能会多次调用只更新一次。相反，应该使用componentDidUpdate生命周期，因为它保证每次更新只调用一次1234567891011// Afterclass ExampleComponent extends React.Component &#123; componentDidUpdate(prevProps, prevState) &#123; if ( this.state.someStatefulValue !== prevState.someStatefulValue ) &#123; this.props.onChange(this.state.someStatefulValue); &#125; &#125;&#125;props改变的副作用(Side effects on props change)与上述 事例类似，有时组件在props更改时会产生副作用12345678// Beforeclass ExampleComponent extends React.Component &#123; componentWillReceiveProps(nextProps) &#123; if (this.props.isVisible !== nextProps.isVisible) &#123; logVisibleChange(nextProps.isVisible); &#125; &#125;&#125;与componentWillUpdate一样，componentWillReceiveProps可能会多次调用但是只更新一次。出于这个原因，避免在此方法中导致的副作用非常重要。相反，应该使用componentDidUpdate，因为它保证每次更新只调用一次：12345678// Afterclass ExampleComponent extends React.Component &#123; componentDidUpdate(prevProps, prevState) &#123; if (this.props.isVisible !== prevProps.isVisible) &#123; logVisibleChange(this.props.isVisible); &#125; &#125;&#125; props改变时获取外部数据(Fetching external data when props change)以下是根据propsvalues提取外部数据的示例12345678910111213141516171819202122232425262728293031323334353637383940// Beforeclass ExampleComponent extends React.Component &#123; state = &#123; externalData: null, &#125;; componentDidMount() &#123; this._loadAsyncData(this.props.id); &#125; componentWillReceiveProps(nextProps) &#123; if (nextProps.id !== this.props.id) &#123; this.setState(&#123;externalData: null&#125;); this._loadAsyncData(nextProps.id); &#125; &#125; componentWillUnmount() &#123; if (this._asyncRequest) &#123; this._asyncRequest.cancel(); &#125; &#125; render() &#123; if (this.state.externalData === null) &#123; // Render loading state ... &#125; else &#123; // Render real UI ... &#125; &#125; _loadAsyncData(id) &#123; this._asyncRequest = asyncLoadData(id).then( externalData =&gt; &#123; this._asyncRequest = null; this.setState(&#123;externalData&#125;); &#125; ); &#125;&#125;此组件的推荐升级路径是将数据更新移动到componentDidUpdate中。在渲染新道具之前，您还可以使用新的getDerivedStateFromProps生命周期清除陈旧的数据：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// Afterclass ExampleComponent extends React.Component &#123; state = &#123; externalData: null, &#125;; static getDerivedStateFromProps(nextProps, prevState) &#123; // Store prevId in state so we can compare when props change. // Clear out previously-loaded data (so we don't render stale stuff). if (nextProps.id !== prevState.prevId) &#123; return &#123; externalData: null, prevId: nextProps.id, &#125;; &#125; // No state update necessary return null; &#125; componentDidMount() &#123; this._loadAsyncData(this.props.id); &#125; componentDidUpdate(prevProps, prevState) &#123; if (this.state.externalData === null) &#123; this._loadAsyncData(this.props.id); &#125; &#125; componentWillUnmount() &#123; if (this._asyncRequest) &#123; this._asyncRequest.cancel(); &#125; &#125; render() &#123; if (this.state.externalData === null) &#123; // Render loading state ... &#125; else &#123; // Render real UI ... &#125; &#125; _loadAsyncData(id) &#123; this._asyncRequest = asyncLoadData(id).then( externalData =&gt; &#123; this._asyncRequest = null; this.setState(&#123;externalData&#125;); &#125; ); &#125;&#125; 在更新之前读取DOM属性(Reading DOM properties before an update)下面是一个组件的例子，它在更新之前从DOM中读取属性，以便在列表中保持滚动位置123456789101112131415161718192021222324252627282930313233343536class ScrollingList extends React.Component &#123; listRef = null; previousScrollOffset = null; componentWillUpdate(nextProps, nextState) &#123; // Are we adding new items to the list? // Capture the scroll position so we can adjust scroll later. if (this.props.list.length &lt; nextProps.list.length) &#123; this.previousScrollOffset = this.listRef.scrollHeight - this.listRef.scrollTop; &#125; &#125; componentDidUpdate(prevProps, prevState) &#123; // If previousScrollOffset is set, we've just added new items. // Adjust scroll so these new items don't push the old ones out of view. if (this.previousScrollOffset !== null) &#123; this.listRef.scrollTop = this.listRef.scrollHeight - this.previousScrollOffset; this.previousScrollOffset = null; &#125; &#125; render() &#123; return ( `&lt;div&gt;` &#123;/* ...contents... */&#125; `&lt;/div&gt;` ); &#125; setListRef = ref =&gt; &#123; this.listRef = ref; &#125;;&#125;在上面的例子中，componentWillUpdate被用来读取DOM属性。但是，对于异步渲染，“render”阶段生命周期（如componentWillUpdate和render）与“commit”阶段生命周期（如componentDidUpdate）之间可能存在延迟。如果用户在这段时间内做了类似调整窗口大小的操作，则从componentWillUpdate中读取的scrollHeight值将失效。 解决此问题的方法是使用新的“commit”阶段生命周期getSnapshotBeforeUpdate。在数据发生变化之前立即调用该方法（例如，在更新DOM之前）。它可以将React的值作为参数传递给componentDidUpdate，在数据发生变化后立即调用它。123456789101112131415161718192021222324252627282930313233343536class ScrollingList extends React.Component &#123; listRef = null; getSnapshotBeforeUpdate(prevProps, prevState) &#123; // Are we adding new items to the list? // Capture the scroll position so we can adjust scroll later. if (prevProps.list.length &lt; this.props.list.length) &#123; return ( this.listRef.scrollHeight - this.listRef.scrollTop ); &#125; return null; &#125; componentDidUpdate(prevProps, prevState, snapshot) &#123; // If we have a snapshot value, we've just added new items. // Adjust scroll so these new items don't push the old ones out of view. // (snapshot here is the value returned from getSnapshotBeforeUpdate) if (snapshot !== null) &#123; this.listRef.scrollTop = this.listRef.scrollHeight - snapshot; &#125; &#125; render() &#123; return ( `&lt;div&gt;` &#123;/* ...contents... */&#125; `&lt;/div&gt;` ); &#125; setListRef = ref =&gt; &#123; this.listRef = ref; &#125;;&#125;]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>lifecycle</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[React Diff算法]]></title>
    <url>%2F2018%2F07%2F18%2FReact-Diff%2F</url>
    <content type="text"><![CDATA[前言React 中最值得称道的部分莫过于 Virtual DOM 与 diff 的完美结合，特别是其高效的 diff 算法，让用户可以无需顾忌性能问题而”任性自由”的刷新页面，让开发者也可以无需关心 Virtual DOM 背后的运作原理，因为 React diff 会帮助我们计算出 Virtual DOM 中真正变化的部分，并只针对该部分进行实际 DOM 操作，而非重新渲染整个页面，从而保证了每次操作更新后页面的高效渲染，因此 Virtual DOM 与 diff 是保证 React 性能口碑的幕后推手 假设树中元素个数为n，最先进的算法 的时间复杂度为O(n3)React基于三点假设，实现了一个启发的O(n)算法 类型相同的节点总是生成同样的树，而类型不同的节点也总是生成不同的树 类型相同的兄弟节点可以被唯一标识 Web UI 中 DOM 节点跨层级的移动操作特别少，可以忽略不计 Diff算法tree diff两棵树只会对同一层次的节点进行比较 component diff 如果是同一类型的组件，按照原策略继续比较 virtual DOM tree 如果不是，则将该组件判断为 dirty component，从而替换整个组件下的所有子节点 对于同一类型的组件，有可能其 Virtual DOM 没有任何变化，如果能够确切的知道这点那可以节省大量的 diff 运算时间，因此 React 允许用户通过 shouldComponentUpdate() 来判断该组件是否需要进行 diff element diff当节点处于同一层级时，React diff 提供了三种节点操作，分别为：INSERT_MARKUP（插入）、MOVE_EXISTING（移动）和 REMOVE_NODE（删除）可以根据key值进行优化 总结 React 通过制定大胆的 diff 策略，将 O(n3) 复杂度的问题转换成 O(n) 复杂度的问题 React 通过分层求异的策略，对 tree diff 进行算法优化 React 通过相同类生成相似树形结构，不同类生成不同树形结构的策略，对 component diff 进行算法优化 React 通过设置唯一 key的策略，对 element diff 进行算法优化 建议，在开发组件时，保持稳定的 DOM 结构会有助于性能的提升 建议，在开发过程中，尽量减少类似将最后一个节点移动到列表首部的操作，当节点数量过大或更新操作过于频繁时，在一定程度上会影响 React 的渲染性能]]></content>
      <categories>
        <category>React</category>
      </categories>
      <tags>
        <tag>diff</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[行存储和（HBase）列存储的区别]]></title>
    <url>%2F2018%2F07%2F11%2FRow-based-storage%2F</url>
    <content type="text"><![CDATA[原理 Row-based storage stores atable in a sequence of rows Column-based storage storesa table in a sequence of columns 优缺点行式存储下一张表的数据都是放在一起的，但列式存储下都被分开保存了。所以它们就有了如下这些优缺点： 列存储为什么快 减少了磁盘IO 随机读变成了连续读]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Huffman-Tree]]></title>
    <url>%2F2018%2F07%2F11%2FHuffman-Tree%2F</url>
    <content type="text"><![CDATA[概览给定n个权值作为n个叶子结点，构造一棵二叉树，若该树的带权路径长度达到最小，称这样的二叉树为最优二叉树，也称为哈夫曼树(Huffman Tree)。 特点哈夫曼树是带权路径长度最短的树，权值较大的结点离根较近。 构造方法假设有n个权值，则构造出的哈夫曼树有n个叶子结点，n个权值分别设为 w1、w2、…、wn 将w1、w2、…，wn看成是有n 棵树的森林(每棵树仅有一个结点) 在森林中选出两个根结点的权值最小的树合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和 从森林中删除选取的两棵树，并将新树加入森林 重复(2)、(3)步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树 注意为了使得到的哈夫曼树的结构尽量唯一，通常规定生成的哈夫曼树中每个结点的左子树根结点的权小于等于右子树根结点的权 应用在数据通信中，让使用频率高的用短码，使用频率低的用长码，以优化整个报文编码]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Huffman Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hash indexes and B-Trees]]></title>
    <url>%2F2018%2F07%2F11%2FB-Trees%2F</url>
    <content type="text"><![CDATA[Hash IndexesBitcaskDeleting records If you want to delete a key and its associated value, you have to append a special deletion record to the data file (sometimes called a tombstone). When log segments are merged, the tombstone tells the merging process to discard any previous values for the deleted key. Crash recovery you can restore each segment’s hash map by reading the entire segment file from beginning to end and noting the offset of the most recent value for every key as you go along. However, that might take a long time if the segment files are large, which would make server restarts painful. Bitcask speeds up recovery by storing a snapshot of each segment’s hash map on disk, which can be loaded into memory more quickly. Concurrency control As writes are appended to the log in a strictly sequential order, a common implementation choice is to have only one writer thread. Data file segments are append-only and otherwise immutable, so they can be read concurrently by multiple threads. append-only design turns out to be good for several reasons: Appending and segment merging are sequential write operations, which are generally much faster than random writes Concurrency and crash recovery are much simpler if segment files are append- only or immutable. For example, you don’t have to worry about the case where a crash happened while a value was being overwritten, leaving you with a file con‐ taining part of the old and part of the new value spliced together. 合并操作能使有用的数据文件更加紧凑 limitations The hash table must fit in memory, so if you have a very large number of keys, you’re out of luck. In principle, you could maintain a hash map on disk, but unfortunately it is difficult to make an on-disk hash map perform well. It requires a lot of random access I/O Range queries are not efficient. SSTables and LSM-TreesSSTable(Sorted String Table) sequence of key-value pairs is sorted by key each key only appears once within each merged segment fileSSTable 优势 Merging segments用了归并排序，保证新合并的segment依然有序，注意当多个segment出现相同的key时，取most recent segment In order to find a particular key in the file, you no longer need to keep an index of all the keys in memory. 取而代之的是一个稀疏的索引You still need an in-memory index to tell you the offsets for some of the keys, but it can be sparse 支持range query disk writes are sequential the LSM-tree can support remarkably high write throughputConstructing and maintaining SSTables When a write comes in, add it to an in-memory balanced tree data structure (for example, a red-black tree). This in-memory tree is sometimes called a memtable. When the memtable gets bigger than some threshold, write it out to disk as an SSTable file In order to serve a read request, first try to find the key in the memtable, then in the most recent on-disk segment, then in the next-older segment, etc. From time to time, run a merging and compaction process in the background to combine segment files and to discard overwritten or deleted values This scheme works very well. It only suffers from one problem: if the database crashes, the most recent writes (which are in the memtable but not yet written out to disk) are lost. In order to avoid that problem, we can keep a separate log on disk to which every write is immediately appended, just like in the previous section. That log is not in sorted order, but that doesn’t matter, because its only purpose is to restore the memtable after a crash. Every time the memtable is written out to an SSTable, the corresponding log can be discarded. Performance optimizations 当查找一个不存在的key时，首先去memtable找，然后从近到远依次找segment，所以为了避免这种情况发生，storage engines often use additional Bloom filters B-TreesConstructing log-structured indexes 将数据拆分成一个个大小可变的segment，并且能够满足顺序写，与之相比的是B-Trees将数据拆分成大小固定的blocks or pages, traditionally 4 KB in size (sometimes bigger), 一次只能读或者写一个page 一个page就是树的一个节点，每个节点指向多个儿子，节点的儿子数量被称为branching factor 当加入一个key的时候，如果符合条件的page空间被占满，这时这个page会被拆分成2个page，然后再更新他们的parent指针Making B-trees reliable write-ahead log (WAL, also known as a redo log)This is an append-only file to which every B-tree modification must be written before it can be applied to the pages of the tree itself, When the data‐base comes back up after a crash, this log is used to restore the B-tree back to a consistent state concurrency control is required if multiple threads are going to access the B-tree at the same time, 此时需要用锁B-tree optimizations Instead of overwriting pages and maintaining a WAL for crash recovery, some databases (like LMDB) use a copy-on-write scheme. 改动过的page会存在另外一个地方，并且它的父亲page会指向这个新儿子 不用存整个key的名称，只存能标识它的‘缩写’，这样可以节约空间，增加一个page的branching factor，从而缩小depth 存在兄弟指针，保证顺序遍历key的时候不用回到父节点 当大范围查询的时候，直接顺序遍历叶子节点Comparing B-Trees and LSM-TreesAs a rule of thumb,LSM-trees are typically faster for writes,whereas B-trees are thought to be faster for reads one write to the database resulting in multiplewrites to the disk over the course of the database’s lifetime—is known as write amplification. LSM-trees 能维持更高的写吞吐量，一部分是因为更小的write amplification，另一部分是因为顺序写真实他妈快啊]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>B-tree</tag>
        <tag>Hash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人民币的汇率控制（贬值）]]></title>
    <url>%2F2018%2F05%2F12%2FRMB-exchange-rate%2F</url>
    <content type="text"><![CDATA[操作方法 经常性干预汇市以维持价位，央行印人民币持续购买美元来降低人民币对美元汇率。于是市场中的人民币增加了，同时可出售央行发行的人民币票据从市场回收人民币起到冲销的作用。持有的美元又通过购买美国国债流到美国和其他投资者手中 资本管制，个人和机构资本流入流出需要获得有关部门审批和授权 通过印人民币来收回贸易顺差中的外币 通过印人民币来收回外国直接投资中国的外币 利 增加出口 增加外汇储备 促进就业 弊 增发本币，通胀 进口商品贵，影响生活水平 出口产业靠高汇率的优势不思进取，产业竞争力变化不大 国内资源被贱卖 出口退税，全国人民的税收来补贴出口]]></content>
      <categories>
        <category>Economics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[经济解释 第一章]]></title>
    <url>%2F2018%2F04%2F10%2Feconomic-explanation%2F</url>
    <content type="text"><![CDATA[现象必有规律现象有规律，自古皆然。我们知其然，但不一定知起所以然。既知其然，就很想知其所以然，这是人的好奇心。我们要作解释，科学也就由此而起。科学的形成基于三个重要信念： 主观判断要客观认同 现象必有规律 现象的发生一定有其原因 推测和解释是同一回事 事实不能解释事实特殊理论与套套逻辑ad hoc theory：内容过多，只能特殊地解释一个现象，没有一般性的解释力科学的进步，不是因为对的理论代替了错的，而是有较广泛解释力的，替代了较狭窄的。特殊理论内容太多了，而套套逻辑则没有内容。可取的理论，一定在特殊逻辑和套套逻辑之间tautology：在任何情况下都不可能错eg：理性经纪人假设、MV=PQ从不同角度看同一数量给套套理论加上约束或局限条件，增加其内容，将其变成理论科学的进步，往往是从一个极端或另一个极端开始，逐步向中间发展 可能被事实推翻的重要性科学不是求对，也不是求错，科学求的是“可能被事实推翻”。可能被事实推翻而没有推翻，就算是被证实（confirmed）了今天可能被事实推翻而没有被推翻的理论，明天可能晚节不保——这是科学进步的过程理论不应该以对或错来衡量refutable by factstestable or refutable implication验证一个理论含意的方法，是以事实反证fallacy of denying the antecedent 模糊不清与互相矛盾可以解释现象的理论，必然有被现象推翻的可能马克思的剩余价值定义模糊，不能被验证，同样也不可能错，警惕“不错就是绝对”四种情况会使一个理论免于被事实推翻的可能： 模糊不清 互相矛盾 非事实 无限制 非事实与无限制需求量本身是抽象的，无法观察的，但是假设需求定律是对的话，价格上涨，需求就下降，这是可以被观察到的事实。这些事实的含义就是需求定律本身（本身不可以被验证的需求定律所推出来的可以被验证的含意）”不均衡“可以解作因为被推断的现象没有限制，理论因而缺少了可能被事实推翻的含意，而”均衡“则是指因为有限制而达到可以验证的理论抽象的理论，本身不能被事实验证；抽象的理论要有解释力，必须又可以被事实验证的一个或多个含意。可验证的含意，要有被事实推翻的可能 理论的真实性三种非真实我们接受： 理论本身必定有抽象成分，因为事实不能解释事实 为了简化 附加的验证条件（test condition） 以抽象思想或概念为起点的科学理论，”非真实“是需要的，因为事实不能自作解释。”不可能太详尽“与”简化“——这些事容许的。但验证条件不能与真实世界脱节 什么是含意（implication）：逻辑包含（logical implication）表明两个陈述或句子存在的关系。这种关系转成口头语言叫做“逻辑上包含”或者“如果就（if/then）”，这个符号由指向右的双线箭头（=&gt;）表示。如果A和B存在这样的状态那么A=&gt;B意思是A逻辑包含B或者如果A那么B。”包含”这个词用语极强可能性的情况]]></content>
      <categories>
        <category>Economics</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[LCA 多次询问 解法总结]]></title>
    <url>%2F2014%2F10%2F28%2FLCA%2F</url>
    <content type="text"><![CDATA[题目N个节点，M次询问，求两点间的最近公共祖先 并查集+DFS（也叫Tarjan）—— 离线O(M+N)每个节点(比如为x)运行完之后就将x的父指针指向它的父亲(这时父亲节点的父指针依然指向自己)，然后再去运行x的兄弟节点，这时兄弟节点下的某个节点(比如y)如果在查询中，且查询如果恰好是(y, x的子孙)，则x所在并查集树中的根节点一定是x的父节点，而这个父节点也是y的祖先，因此可知(y, x的子孙)的祖先一定包含x的父节点，由上面过程知道不能可包含比x的父节点更低的祖先节点，因此x的祖先节点必然是(y, x的子孙)的最近公共祖先)；123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;cstdio&gt;#include &lt;algorithm&gt;#include &lt;vector&gt;using namespace std;#define N 10100vector &lt;int&gt; a[N];int vis[N],fa[N],In[N];int l,r;void ini()&#123; for(int i = 0; i &lt; N; i++)a[i].clear();//存树 for(int i = 0; i &lt; N; i++)vis[i]=0;//存是否被处理过 for(int i = 0; i &lt; N; i++)fa[i]=i; for(int i = 0; i &lt; N; i++)In[i]=0;//存每个节点的入度&#125;int get_fa(int x)&#123; if(x==fa[x])return x; return fa[x]=get_fa(fa[x]);&#125;void LCA(int u)&#123; int len=a[u].size(); for(int i = 0; i &lt; len; i++) &#123; int v=a[u][i]; LCA(v); fa[v]=u; &#125; vis[u]=1; if((l==u&amp;&amp;vis[r])) //此时l,r不在以u为根的子树上，且r那颗子树已经处理完毕，fa[r所在子树的根]=l,r共同的祖先（已经赋过值），所以get_fa(r); printf("%d\n",get_fa(r)); if(r==u&amp;&amp;vis[l]) printf("%d\n",get_fa(l));//同理 //printf("haha\n");&#125;int main()&#123; int t;scanf("%d",&amp;t); while(t--) &#123; int n;scanf("%d",&amp;n); ini(); for(int i = 1; i &lt; n; i++) &#123; int x,y; scanf("%d%d",&amp;x,&amp;y); a[x].push_back(y); In[y]++; &#125; scanf("%d%d",&amp;l,&amp;r); // printf("haha\n"); for(int i = 1; i &lt;= n; i++) if(!In[i])LCA(i); &#125; return 0;&#125; 裸RMQ——–在线（N(log N)预处理，每次 log N 查询） O（N(log N)+M(log N)）设P[i][j]表示结点i往上移动2^j步所到达的结点，P[i][j]可以通过以下递推公式计算：利用P数组可以快速的将结点i向上移动n步，方法是将n表示为2进制数。比如n=6，二进制为110，那么利用P数组先向上移动4步(2^2)，然后再继续移动2步(2^1)，即P[ P[i][2] ][1]。 预处理计算P数组代码如下12345678910111213141516171819202122232425map&lt;TreeNode*, int&gt; nodeToId;map&lt;int, TreeNode*&gt; idToNode;const int MAXLOGN=20; //树中最大结点数为1&lt;&lt;20int P[1 &lt;&lt; MAXLOGN][MAXLOGN];//allNodes存放树中所有的结点void preProcessTree(vector&lt;TreeNode *&gt; allNodes) &#123; int n = allNodes.size(); // 初始化P中所有元素为-1 for (int i = 0; i &lt; n; i++) for (int j = 0; 1 &lt;&lt; j &lt; n; j++) P[i][j] = -1; for (int i = 0; i &lt; n; i++) &#123; nodeToId[allNodes[i]] = i; idToNode[i] = allNodes[i]; &#125; // P[i][0]=parent(i) for (int i = 0; i &lt; n; i++) P[i][0] = allNodes[i]-&gt;parent ? nodeToId[allNodes[i]-&gt;parent] : -1; // 计算P[i][j] for (int j = 1; 1 &lt;&lt; j &lt; n; j++) for (int i = 0; i &lt; n; i++) if (P[i][j] != -1) P[i][j] = P[P[i][j - 1]][j - 1];&#125;另外我们还需要预处理计算出每个结点的深度L[]，预处理之后，查询node1和node2的LCA算法如下12345678910111213141516171819TreeNode* getLCA(TreeNode *node1, TreeNode *node2, int L[]) &#123; int id1 = nodeToId[node1], id2 = nodeToId[node2]; //如果node2的深度比node1深，那么交换node1和node2 if (L[id1] &lt; L[id2]) swap(id1, id2); //计算[log(L[id1])] int log; for (log = 1; 1 &lt;&lt; log &lt;= L[id1]; log++); log--; //将node1向上移动L[id1]-L[id2]步，使得node1和node2在同一深度上 for (int i = log; i &gt;= 0; i--) if (L[id1] - (1 &lt;&lt; i) &gt;= L[id2]) id1 = P[id1][i]; if (id1 == id2) return idToNode[id1]; //使用P数组计算LCA(idToNode[id1], idToNode[id2]) for (i = log; i &gt;= 0; i--) if (P[id1][i] != -1 &amp;&amp; P[id1][i] != P[id2][i]) id1 = P[id1][i], id2 = P[id2][i]; return idToNode[id1];&#125; 时间复杂度分析：假设树包含n个结点，由于P数组有nlogn个值需要计算，因此预处理的时间复杂度为O(nlogn)。查询两个结点的LCA时，函数getLCA中两个循环最多执行2logn次，因此查询的时间复杂度为O(logn) LCA转化为RMQ——–在线（N(log N)预处理，每次 O(1) 查询） O（N(log N)+M）对于有根树T的两个结点u、v，最近公共祖先LCA(T,u,v)表示一个结点x，满足x是u、v的祖先且x的深度尽可能大。另一种理解方式是把T理解为一个无向无环图，而LCA(T,u,v)即u到v的最短路上深度最小的点。这里给出一个LCA的例子：例一对于T=&lt;V,E&gt;V={1,2,3,4,5}E={(1,2),(1,3),(3,4),(3,5)}则有：LCA(T,5,2)=1LCA(T,3,4)=3LCA(T,4,5)=3 RMQ问题与LCA问题的关系紧密，可以相互转换，相应的求解算法也有异曲同工之妙。下面给出LCA问题向RMQ问题的转化方法。 对树进行深度优先遍历，每当“进入”或回溯到某个结点时，将这个结点的编号存入数组E最后一位。同时记录结点i在数组中第一次出现的位置(事实上就是进入结点i时记录的位置)，记做R[i]。如果结点E[i]的深度记做D[i]，易见，这时求LCA(T,u,v)，就等价于求E[RMQ(D,R[u],R [v])]，(R[u]&lt;R[v])，其中RMQ(D,R[u],R [v])就是在D数组中求下标从R[u]到R[v]的最小值的下标。例如一，求解步骤如下： 数列E[i]为：1,2,1,3,4,3,5,3,1 R[i]为：1,2,4,5,7 D[i]为：0,1,0,1,2,1,2,1,0 于是有： LCA(T,5,2) = E[RMQ(D,R[2],R[5])] = E[RMQ(D,2,7)] = E[3] = 1 LCA(T,3,4) = E[RMQ(D,R[3],R[4])] = E[RMQ(D,4,5)] = E[4] = 3 LCA(T,4,5) = E[RMQ(D,R[4],R[5])] = E[RMQ(D,5,7)] = E[6] = 3 易知，转化后得到的数列长度为树的结点数的两倍减一， 所以转化后的RMQ问题与LCA问题的规模同次 再举一个例子帮助理解: (1) / \ (2) (7) / \ \(3) (4) (8) / \(5) (6)一个nlogn 预处理，O(1)查询的算法. Step 1: 按先序遍历整棵树，记下两个信息:结点访问顺序和结点深度. 如上图: 结点访问顺序是: 1 2 3 2 4 5 4 6 4 2 1 7 8 7 1 //共2n-1个值 结点对应深度是: 0 1 2 1 2 3 2 3 2 1 0 1 2 1 0 Step 2: 如果查询结点3与结点6的公共祖先,则考虑在访问顺序中 3第一次出现，到6第一次出现的子序列: 3 2 4 5 4 6. 这显然是由结点3到结点6的一条路径. 在这条路径中，深度最小的就是最近公共祖先(LCA). 即 结点2是3和6的LCA. Step 3: 于是问题转化为, 给定一个数组R,及两个数字i,j,如何找出 数组R中从i位置到j位置的最小值.. 如上例,就是R[]={0,1,2,1,2,3,2,3,2,1,0,1,2,1,0}. i=2;j=7; 接下来就是经典的RMQ问题.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;cmath&gt;#include &lt;algorithm&gt;using namespace std;#define maxn 100010int cnt,id;int head[maxn];bool vis[maxn];int dep[maxn*2+1], E[maxn*2+1], R[maxn];//R表示节点第一次出现的位置；dep表示时间戳为i时的深度；E表示时间戳为i时的节点int f[maxn*2+1][20],d[50]; //f[] is RMQ, d[i] is 2^istruct Edge&#123; int to,next,weight;&#125;edges[maxn]; //邻接表void init()&#123; cnt=id=0; memset(vis,false,sizeof(vis)); memset(head,-1,sizeof(head));&#125; void insert(int a, int b, int weight)&#123; edges[cnt].to=b; edges[cnt].next=head[a]; edges[cnt].weight=weight; head[a]=cnt++;&#125;void DFS(int u, int d)&#123; vis[u]=1; R[u]=id;E[id]=u;dep[id++]=d; for(int i = head[u]; i != -1; i=edges[i].next) &#123; int v=edges[i].to; if(!vis[v]) &#123; DFS(v,d+1); E[id]=u;dep[id++]=d; &#125; &#125;&#125;void InitRMQ(const int &amp;id,int n)&#123; d[0]=1; for(int i = 1; i &lt; n; i++)d[i]=2*d[i-1]; for(int i = 0; i &lt; id; i++)f[i][0]=i; int k=int(log(double(n))/log(2.0))+1; for(int j = 1; j &lt; k; j++) for(int i = 0; i &lt; id; i++) &#123; if(i+d[j-1]-1&lt;id) f[i][j]=dep[f[i][j-1]]&gt;dep[f[i+d[j-1]][j-1]]?f[i+d[j-1]][j-1]:f[i][j-1]; else break; &#125;&#125;int Query(int x, int y)&#123; int k; k=int(log(double(y-x+1))/log(2.0)); return dep[f[x][k]]&gt;dep[f[y-d[k]+1][k]]?f[y-d[k]+1][k]:f[x][k];&#125;void Answer()&#123; int Q;scanf("%d",&amp;Q); for(int i = 0; i &lt; Q; i++) &#123; int x,y; scanf("%d%d",&amp;x,&amp;y); //查询x,y的LCA x=R[x];y=R[y]; if(x&gt;y)swap(x,y); printf("%d\n",E[Query(x,y)]); &#125;&#125;int main()&#123; int t;scanf("%d",&amp;t); while(t--) &#123; init(); int n,m;scanf("%d%d",&amp;n,&amp;m); for(int i = 0; i &lt; m; i++) &#123; int a,b,c;scanf("%d%d%d",&amp;a,&amp;b,&amp;c); insert(a,b,c); &#125; DFS(1,0); InitRMQ(id,n); Answer(); &#125; return 0;&#125;]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>LCA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Suffix Tree 后缀数组]]></title>
    <url>%2F2013%2F03%2F28%2Fsuffix-tree%2F</url>
    <content type="text"><![CDATA[前言这是13年3月28日的文章，那时的我在机房熬了一天一夜翻来覆去看罗穗骞的代码，最后才把这个后缀数组给整明白了，故有此文现在的我回想那过去的岁月，难免唏嘘不已，今时今日借整理此文，以缅怀那过去的岁月吧！原文链接 声明我的模板是根据 罗穗骞 和 网上一模板 相结合改编而来，层次更加分明，数组名称的选择是根据用途来定义的，总的来说应该更好理解一些先声明一些概念： k-后缀数组：我这里用的是 sa[ ] ( k ) k-名次数组：我这里用的是 rank[ ] ( k ) 思路知道rank[ ] (1) 先求出sa[ ] (1)，然后根据 sa[ ] (1) 和 rank[ ] (1) 调用sorting函数求出 sa[ ] (2)，再求出rank[ ] (2) 等等 总的过程是rank[ ] (1)—-&gt;sa[ ] (1) —&gt;rank[ ] (2) —&gt; sa[ ] (2) —&gt; rank[ ] (k) —-&gt;sa[ ] (k) Hint 我的数组小标全是从1开始的，程序运行前一定要初始化函数ini() 其它该有的东西都在代码里，建议一边看代码下面的图，一边理解！ 模板代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110#include &lt;cstdio&gt;#include &lt;cstring&gt;#include &lt;algorithm&gt;#include &lt;cmath&gt;using namespace std;#define N 3000//处理完成之后下标都是从1开始char s[N];//存原始数据int sum[N], rank[2*N], trank[2*N];//sum用来基数排序；trank === temp-rankint sa[N], tsa[N]; //这里tsa[]用来保存第二关键字排序后的结果int Top, n; //Top基数排序出现的极大值void ini() //初始化&#123; n=strlen(s); memset(sum,0,sizeof(sum)); memset(rank,0,sizeof(rank)); memset(sa,0,sizeof(sa)); Top=128;&#125;void sorting(int k)&#123; int p = 1; //利用sa排序第二关键字，求出tsa for(int i = n-k+1; i &lt;= n; i++) tsa[p++]=i; //超出范围的下标按下标顺序置其名次为最低 for(int i = 1; i &lt;= n; i++) if(sa[i]&gt;=k+1) tsa[p++]=sa[i]-k; //按sa排名从小到大遍历，如果排名为i的某后缀(sa[i])位置在k后面，那么这个后缀肯定会在第二关键字排序 //(tsa[])中出现并且排在比较靠前的位置，这个后缀对应tsa[]中的位置为sa[i]-k memset(sum,0,sizeof(sum)); for(int i = 1; i &lt;= n; i++)sum[rank[i]]++; for(int i = 1; i &lt;= Top; i++)sum[i]+=sum[i-1]; for(int i = n; i &gt; 0; i--)sa[sum[rank[tsa[i]]]--]=tsa[i];//这句话应该是关键 //如果把tsa[i]换成i，那么就是对rank[i]按第一关键字排序求sa[]，事实上这段程序也是这样， //不过把i换成tsa[i]后会多一个功能，就是按第一关键字排序rank相同的情况下，会按第二关键字排， //这也正符合我们最终要求的sa[](2k)。具体方法是从tsa[n]到tsa[1]，让在第二关键字排名靠后的优先 //取sum较大的，取一次，sum--，如果后边第二关键字排名靠前的某后缀在第一关键字下rank和它相同， //那么它的sum就较小，在sa中排名就会靠前，服从排序规律！&#125;void get_sa()&#123; int p; for(int i = 0; i &lt; n; i++) rank[i+1]=s[i]; //仔细想一下，其实此时rank就是rank[](1); for(int i = 1; i &lt;= n; i++) sum[rank[i]]++; for(int i = 1; i &lt;= Top; i++) sum[i]+=sum[i-1]; //sum[i] means the number of the &lt;= rank[i]; for(int i = n; i &gt; 0; i--) sa[sum[rank[i]]--]=i; //sa[](1)构造完成 for(int k = 1; k &lt;= n; k&lt;&lt;=1) &#123; sorting(k); //由sa[](k)和rank[](k) 求 sa[](2k) //求rank[](2k) trank[sa[1]]=1; p=1; for(int i = 2; i &lt;= n; i++) &#123; if((rank[sa[i]]!=rank[sa[i-1]])||(rank[sa[i]+k]!=rank[sa[i-1]+k]))p++; trank[sa[i]]=p; &#125; for(int i = 1; i &lt;= n; i++)rank[i]=trank[i]; if(p&gt;=n)break; //rank[1,2……n]已经唯一了，即后缀大小已经唯一确定了，不需要继续执行了 Top=p;//下次基数排序的最大值 &#125;&#125;int height[N];void get_height()&#123; for(int i = 1, j = 0; i &lt;= n; i++) &#123; if(rank[i]==1)continue; for(;s[i+j-1]==s[sa[rank[i]-1]+j-1];)j++;//i从1开始，所以在原串中要-1 height[rank[i]]=j; if(j&gt;0)j--; &#125;&#125; int *RMQ=height;int mm[N];int best[20][N];void initRMQ(int n)&#123; int i,j,a,b; for(mm[0]=-1,i=1; i&lt;=n; i++) mm[i]=((i&amp;(i-1))==0)?mm[i-1]+1:mm[i-1]; for(i=1; i&lt;=n; i++)best[0][i]=i; for(i=1; i&lt;=mm[n]; i++)for(j=1; j&lt;=n+1-(1&lt;&lt;i); j++) &#123; a=best[i-1][j]; b=best[i-1][j+(1&lt;&lt;(i-1))]; if(RMQ[a]&lt;RMQ[b])best[i][j]=a; else best[i][j]=b; &#125;&#125;int askRMQ(int a,int b)&#123; int t; t=mm[b-a+1]; b-=(1&lt;&lt;t)-1; a=best[t][a]; b=best[t][b]; return RMQ[a]&lt;RMQ[b]?a:b;&#125;//求sufix(a)与sufix(b)的最长公共前缀长度，用上面的RMQ优化int lcp(int a,int b) //这里的a,b是字符串当中的位置，注意要从1开始&#123; int t; a=rank[a],b=rank[b]; if(a&gt;b) &#123; t=a; a=b; b=t; &#125; return height[askRMQ(a+1,b)];&#125; h[i] &gt;= h[i-1]-1的证明设suffix(k)是排在suffix(i-1)前一位的后缀，则它们的最长公共前缀显然是h[i-1]。那么，suffix(k+1)显然将排在suffix(i)的前面。并且，suffix(k+1)&amp;suffix(i) 相对于 suffix(k)&amp;suffix(i-1)来说就是同时去掉了第一位，即少了一位的匹配数。所以suffix(i)和前一名次后缀的最长公共前缀至少是h[i-1]-1 为什么是 至少h[i-1]-1的理解根据上面的证明我们可以得到suffix(k+1)&amp;suffix(i) == h[i-1]-1又因为suffix(k+1)显然将排在suffix(i)的前面所以 LCP(k+1,i) = h[i-1]-1 =min{ LCP(j-1, j) |k+1 ≤j ≤i } （LCP Theorem）&lt;= h[i]@(数据结构)]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Suffix Tree</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博弈进行时]]></title>
    <url>%2F2012%2F12%2F04%2Fgame-theory%2F</url>
    <content type="text"><![CDATA[前言这是 2012年12月04日 00:13:42 发表的博客，那时的我初生牛犊不怕虎，天天都在做final梦，在数据结构、动态规划还没整明白的情况下贸然开始搞博弈，实乃too simple。博弈现在基本上是忘到爪哇岛去了，投入的精力不知道还剩几斤几两。不过想想当年，确实挺热血的嘛！ 小知识点HDOJ2176 取(m堆)石子游戏 [输出第一步走法] 若给出的是必胜状态：a1^a2^…….^an=k,(其中k不为零)，那么我们的目的是要把必胜状态转化为必败状态从 而使得先手胜利。 若a1^a2^…^an!=0，一定存在某个合法的移动，将ai改变成ai’后满足a1^a2^…^ai’^…^an=0。 若a1^a2^…^an=k，则一定存在某个ai，它的二进制 表示在k的最高位上是1（否则k的最高位那个1是怎么得到的）。这时ai^k&lt;ai一定成立。 则我们可以将ai改变成ai’=ai^k，此时a1^a2^…^ai’^…^an=a1^a2^…^an^k=0 HDOJ1907&amp;&amp;POJ3480&amp;ZOJ3113 John [ANTI-SG]必胜策略： sg值为0 且 全为孤单堆； sg值不为0 且 不全为孤单堆； NP暴力打表||找规律HDOJ1525&amp;POJ2348 Euclid’s Game [找规律博弈]注意第一次出现a/b&gt;1的位置为必胜 HDOJ1564 Play a game [找规律]（重点是打表的方法，N P定理）打表发现奇偶性规律 HDOJ1404 Digital Deletions [SG博弈]（暴力打表，NP定理）老实说，这个表不太好打。从P-&gt;N一种是在让某一位增加；另一种是在后面补0 裸求sg值HDOJ3032 Nim or not Nim? [找规律]SG打表重点是sg函数的求法，把一堆变成两堆，有嵌套的感觉。 HDOJ1729 Stone Game [SG博弈]这题我开始打了个表，，什么规律都没找出来，还是得靠分析，，可我不会啊。。。。 我的理解：可以先模拟一下，初始为（27,2），子递归状态为（4,2）然后返回2，结束。然后我从前往后推，A先拿2个，变为（27,4）状态，然后无论B怎么拿都无法拿完，所以B很保守的只拿一个，变为（27,5）状态，然后A轻松拿完；所以A获胜了。所以我的理解是子递归状态返回值的意义在于 先手能否成功到达必败点，让后手必败。 那么对于这题对于每一堆，放石子放满就想当于满的时候取s-c个，反向只是让我理解题意更深。 首先我们知道（S，S）这个局面是必败局面。 对于每一堆能加的数量有限，而当c的值（大于或者等于）D=sqrt(s) 或者 D=sqri（s）+1的时候就可以一次完成，就是说可以从当前局面到达（S，S）的局面，所以当前局面是必胜局面。 而这种情况下，你能造成的局面有集合A={0,1,2,…,s-c-1}；因为你可以去s-c，s-c-1，s-c-2，…..，1；那么对应mex(x)函数（即A中未出现的最小的一个数字），那么自然该局面的SG值就是s-c了； 另外当c的值小于D的时候，是不可能一下子加满的，因为c*c+c绝对是小于s的；那么小于D的局面一定能够是必输的吗？很显然不是的。 对于（S，D-1）这个局面，一定是必输，因为他能到的局面都是必胜！现在c小于D，那么如果（S，C）这个局面能到（S，D）；就代表这个局面是必胜的。所以现在SG值要在新集合（D，C）中求，而求法与上面的相同求新的D，所以可以用递归函数：当C&gt;D时，返回（S-C） 差不多就是这样。 其实D = sqrt(s);这里算是个加速，要不然就要：while(d*d+d &lt; S) d++;这样会很慢的。 思路：这题明显的sg函数。可惜我纠结了半天没想起思路来。设当前的箱子容量为si，求出一个t满足：t + t * t &lt; si，若是当前箱子里有ci颗石头， ci &gt; t 则必胜； ci == t 则必败； ci &lt; t不可立即断定，将t作为si递归调用函数。 当满足ci &gt; t时，return si - ci 作为当前状况的sg值。因为： 当ci在si点时，为有向图的端点，出度为0，也就是必败点，所以sg值为0； 当ci 位于si - 1时，ci的端点可能的sg值构成的凑集为{0}，所以当前sg值 为1； 当ci 位于si - 2 时，ci的端点可能的sg值构成的凑集为{0， 1}，所以当前的sg值为2； 可得，ci地点地位的sg值为si - ci； [TopCoder]SRM 561 DIV1 500：CirclesGame题意：给你n&lt;=50个不相交的圆（可能包含）。Alice 和Bob博弈，Alice先手，每次每人都可以选择一个没有红点的圆，在圆内放置一个红点，最后没法放红点的一方失败。 算法分析：圆与圆没有相交，故可以把每个圆看成一个结点，直接包含看成点与点之间的边，于是得到一个森林。原题变成在这个森林里博弈，每次选取一个结点，可以干掉他和他的所有祖先结点，干掉最后一个点的获胜。首先我们来考虑每颗树的sg函数。我们可以选择这棵树上任意一个结点操作，去掉这个结点以及其祖先结点后剩下的树的sg函数取异或便是当前操作所得状态的sg值，去掉这些sg值，剩下sg值的最小值即为这棵树的sg函数（看不懂的先好好学学博弈论）。求出每颗树的sg函数，最后取异或便是最终的sg函数，结果不等于0先手胜否则后手胜。 （这题不太好写，子状态神马递归容易出错） starcaseHDOJ3389 Game [Staircase Nim]变形要注意这类博弈的特点：一定是奇堆移动到偶堆，偶堆移动到奇堆。 题意：有N堆石子，每堆石子都有一定的石子数，Alice和Bob轮流玩一个游戏，游戏的规则是，每回合一个人可以选择1-n堆石子中的某一堆进行操作，操作是：假设选择操作的那堆石子的编号为A，现在还要选择一堆石子B，满足B&lt;A &amp;&amp; (A+B)%2==1 &amp;&amp; (A+B)%3==0，然后可以将A中至少一颗石子移到B中去，第一个不能进行合法操作的人输，问谁能赢。 思路：这是一个阶梯博弈的题目，首先我们可以发现，只有1 ，3 ，4 三个数是没有前缀的， 也就是terminal状态，其余的每个状态我们都可以计算出每个编号到这几个terminal的步数（当然有的编号的步数并不唯一，但是奇偶性是唯一的）。接下去我们就会发现，每次从一个奇数步的点，一定是要移到到 一个偶数步的点上去，也就是说每次只能移到奇数步，这个通过编号自身的奇偶性就可以证明了。这样就转化为了阶梯博弈的类型了，我们只需要关注奇数步编号出的石子的数量就可以了，如果奇数步编号处的石子的Nim和为0，则必败，不为0则必胜。接下去我们就简单地证明一下这个策略：如果移动的是奇数步位置的石子，则一定是移动到偶数步的位置，这时候我们只需要按照Nim博弈的必胜策略进行游戏就可以赢；如果移动的是偶数步数编号位置的石子，则移动是移动到奇数步的位置，这时候我们只需要将刚刚移动过来的石子移动到下一个偶数步位置，原来的Nim局面并没有变化，变化的只是偶数步石子的数量。这样我们就证明了原游戏可以转化为Nim游戏。 POJ1704 Georgia and Bob [阶梯博弈] (下面一题是这个的加强版，直接把这种最纯粹的看做模型)我们把棋子按位置升序排列后，从后往前把他们两两绑定成一对。如果总个数是奇数，就把最前面一个和边界（位置为0）绑定。在同一对棋子中，如果对手移动前一个，你总能对后一个移动相同的步数，所以一对棋子的前一个和前一对棋子的后一个之间有多少个空位置对最终的结果是没有影响的。于是我们只需要考虑同一对的两个棋子之间有多少空位。这样一来就成了N堆取石子游戏了. HDOJ4315 Climbing the Hill [阶梯博弈] （有待提高）这题压力山大，看了好久： 此题的简化版本是不考虑King的存在，双方一直走到不能走的一方为负。此时的解法是根据人数的奇偶性：把人从上顶向下的位置记为a1,a2,…an, 如果为偶数个人，则把a(2i-1)和a(2i)之间的距离当做一个Nim堆，变成一共n/2堆的Nim游戏；如果为奇数个人，则把山顶到a1的距离当做一个Nim堆，a(i2)到a(i2+1)的距离当做Nim堆，一共(n+1)/2堆。 考虑King的情况和上述版本几乎一致，只要把King当作普通人一样处理即可。除了两种特殊情况：1. 当King是第一个人时，Alice直接胜 2. 当King是第二个人且一共有奇数个人时，第一堆的大小需要减1。 题意如上图所示：有 n 个球分别在 n 个不同的位置，Alice 和 Bob 依次选择一个球向上移动，上面有球不能越过，谁最后把红球移出谁就赢！ 分析1、n 为偶数时：问题简化一下，假设全都是黄球，谁把最后一个球移出谁就赢（a1,a2） (a3,a4) …… ( a(2n-1) , a(2n) ) ……（a(n-1),an）其中第 i 个球与第 i+1 个球是相邻的，i 为基数，谁面对这个状态谁就必输。理由很简单，先手移动第 i 个球，后手移动第 i+1 个球，使之仍然保持必赢状态。回到原问题谁先移出红球谁就赢，假设红球不是第一个球（因为第一个球Alice直接就赢了）很显然如果红球在偶数位置后手必赢，如果在基数 i 位置，则只需将 第 i-1 个球移到第一个位置就ok了。所以与红球位置无关。至于产生这个状态（a1,a2） (a3,a4) …… ( a(2n-1) , a(2n) ) ……（a(n-1),an），那么就是简单的 Nim问题了2、n 为基数时：假设红球是第1、2个球。（a1） (a2,a3)（a4,a5）…… (a(2n),a(2n+1)) …… (a(n-1),an) 谁面对这个状态必赢！理由是先手直接把 a1 取走然后就变成上面的情况了，如果红球在第 2 个位置那么就是必输状态。 与staircase的联系：对于这个题目，从后向前两两划分成一组，组内相当于奇数阶梯上的石子，组间相当于偶数阶梯上的石子，移动组内的前面石子一定能够通过移动当前组的后面石子相同步数达到平衡态，移动组内后面的石子一定能够通过移动其他组后面石子达到平衡态，具体因为King的原因需要处理细节，上面已经说清楚了，不再赘述。 翻硬币游戏HDOJ3537 Daizhenyang’s Coin[翻硬币游戏]SG打表 （待解决）这题表我是打出来了，规律没找出来（注意还要对编号排序判重） HDOJ3951 Coin Game [找规律]题意给你n个硬币排成一圈，编号1-n,只能翻转连续的1~k个的硬币。翻最后一枚硬币者赢。 思路博弈 若k=1,则一次只能去翻一枚，奇数先手赢，偶数后手赢。 若k&gt;1: 先手一次翻完，先手赢； 先手不能翻完，第一次必定断环。只要后手一次翻完，或将其分为相等数量的两段， 之后先手怎么操作后手就怎么操作，后手必赢。 树&amp;&amp;删边HDOJ3094 A tree game[有向无环树形图SG博弈]最基础的删边 HDOJ3197 Game[树形SG博弈]砍树树的删边游戏，把多棵树的根异或起来就行了 HDOJ3590 PP and QQ[树的删边游戏+ANTI-SG]先手必胜当且仅当 游戏的SG函数不为0且游戏中某个单一游戏的SG函数大于1 游戏的SG函数为0且游戏中没有单一游戏的SG函数大于1 POJ3710 Christmas Game[无向图删边]Tarjan算法找出环，处理环之后，便是经典的删边游戏。拥有奇数条边的环可简化为一条边，偶数条边的环可简化为一个节点。]]></content>
      <categories>
        <category>Game theory</category>
      </categories>
      <tags>
        <tag>Nim</tag>
        <tag>SG</tag>
      </tags>
  </entry>
</search>
